{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found files: ['ecmaffil\\\\ajecm.tab', 'ecmaffil\\\\drecm.tab', 'ecmaffil\\\\efecm.tab', 'ecmaffil\\\\enecm.tab', 'ecmaffil\\\\mbecm.tab', 'ecmaffil\\\\mdecm.tab', 'ecmaffil\\\\mlecm.tab', 'ecmaffil\\\\mmecm.tab', 'ecmaffil\\\\moecm.tab', 'ecmaffil\\\\paecm.tab', 'ecmaffil\\\\pdecm.tab', 'ecmaffil\\\\pgecm.tab', 'ecmaffil\\\\phecm.tab', 'ecmaffil\\\\pkecm.tab', 'ecmaffil\\\\pnecm.tab', 'ecmaffil\\\\pvecm.tab', 'ecmaffil\\\\raecm.tab', 'ecmaffil\\\\rfecm.tab', 'ecmaffil\\\\sbecm.tab']\n",
      "DataFrames loaded: ['ajdf', 'drdf', 'efdf', 'endf', 'mbdf', 'mddf', 'mldf', 'mmdf', 'modf', 'padf', 'pddf', 'pgdf', 'phdf', 'pkdf', 'pndf', 'pvdf', 'radf', 'rfdf', 'sbdf']\n",
      "ajdf head:\n",
      "        qseqid            sseqid  pident  length  mismatch  gapopen  qstart  \\\n",
      "0  NP_002988.3  ajXP_053523075.1   0.722     310        85        0       1   \n",
      "1  NP_002989.2  ajXP_036986998.2   0.905     201        19        0       1   \n",
      "2  NP_055469.3  ajXP_037005331.2   0.914     442        38        0       1   \n",
      "3  NP_005561.1  ajXP_037007848.2   0.905     518        48        0       1   \n",
      "4  NP_005561.1  ajXP_053520215.1   0.905     518        48        0       1   \n",
      "\n",
      "   qend  sstart  send         evalue  bitscore  \n",
      "0   310       1   306  2.124000e-139       441  \n",
      "1   201       1   201  1.333000e-116       369  \n",
      "2   442       1   442  2.225000e-266       815  \n",
      "3   510       1   518   0.000000e+00      1001  \n",
      "4   510       1   518   0.000000e+00      1001  \n",
      "drdf head:\n",
      "           qseqid            sseqid  pident  length  mismatch  gapopen  \\\n",
      "0     NP_000691.1  drXP_053779718.1   0.889     345        38        0   \n",
      "1  XP_005255991.1  drXP_024411733.2   0.864     434        59        0   \n",
      "2     NP_002072.2  drXP_024420041.2   0.863     558        76        0   \n",
      "3     NP_689955.1  drXP_024427142.1   0.745     579       145        0   \n",
      "4     NP_001439.2  drXP_024422721.2   0.928     556        40        0   \n",
      "\n",
      "   qstart  qend  sstart  send         evalue  bitscore  \n",
      "0       1   345       1   345  8.287000e-204       629  \n",
      "1      13   445      17   450  8.988000e-271       828  \n",
      "2       1   558       1   557   0.000000e+00      1008  \n",
      "3       1   579       1   571  1.375000e-288       887  \n",
      "4       1   556       1   556   0.000000e+00      1086  \n",
      "efdf head:\n",
      "           qseqid            sseqid  pident  length  mismatch  gapopen  \\\n",
      "0     NP_940995.1  efXP_054565619.1   0.786     281        60        0   \n",
      "1     NP_940995.1  efXP_054565620.1   0.786     281        60        0   \n",
      "2     NP_940995.1  efXP_054565621.1   0.786     281        60        0   \n",
      "3     NP_036563.1  efXP_008147770.2   0.936     775        50        0   \n",
      "4  XP_005265438.1  efXP_054585805.1   0.961     785        31        0   \n",
      "\n",
      "   qstart  qend  sstart  send         evalue  bitscore  \n",
      "0       1   281       1   281  3.095000e-151       473  \n",
      "1       1   281       1   281  3.095000e-151       473  \n",
      "2       1   281       1   281  3.095000e-151       473  \n",
      "3       1   775       1   775   0.000000e+00      1556  \n",
      "4       1   785       1   785   0.000000e+00      1613  \n",
      "endf head:\n",
      "           qseqid          sseqid  pident  length  mismatch  gapopen  qstart  \\\n",
      "0  XP_005268489.1  enKAK1343476.1   0.947     401        21        0      33   \n",
      "1     NP_004025.1  enKAK1333779.1   0.601     554       194        0       1   \n",
      "2     NP_003559.2  enKAK1329070.1   0.826     345        60        0       1   \n",
      "3     NP_057075.1  enKAK1340395.1   0.775     245        55        0       1   \n",
      "4     NP_065962.1  enKAK1335128.1   0.859    1147       148        0     502   \n",
      "\n",
      "   qend  sstart  send         evalue  bitscore  \n",
      "0   433       1   401  1.046000e-246       769  \n",
      "1   488       1   554  3.848000e-188       590  \n",
      "2   345       1   345  1.559000e-181       563  \n",
      "3   245      67   311  6.515000e-133       417  \n",
      "4  1555      49  1195   0.000000e+00      2003  \n",
      "mbdf head:\n",
      "           qseqid            sseqid  pident  length  mismatch  gapopen  \\\n",
      "0  NP_001129686.1  mbXP_005862692.1   0.835     450        73        0   \n",
      "1  NP_001129686.1  mbXP_014392235.1   0.835     450        73        0   \n",
      "2  NP_001258126.1  mbXP_005862692.1   0.835     450        73        0   \n",
      "3  NP_001258126.1  mbXP_014392235.1   0.835     450        73        0   \n",
      "4     NP_872425.2  mbXP_005862692.1   0.835     450        73        0   \n",
      "\n",
      "   qstart  qend  sstart  send         evalue  bitscore  \n",
      "0       1   445       1   450  4.933000e-265       811  \n",
      "1       1   445       1   450  4.933000e-265       811  \n",
      "2       1   445       1   450  4.933000e-265       811  \n",
      "3       1   445       1   450  4.933000e-265       811  \n",
      "4       1   445       1   450  4.933000e-265       811  \n",
      "mddf head:\n",
      "        qseqid            sseqid  pident  length  mismatch  gapopen  qstart  \\\n",
      "0  NP_114116.3  mdXP_059537609.1   0.691     266        80        0      20   \n",
      "1  NP_114116.3  mdXP_059537610.1   0.691     266        80        0      20   \n",
      "2  NP_114116.3  mdXP_059537611.1   0.691     266        80        0      20   \n",
      "3  NP_114116.3  mdXP_059537612.1   0.691     266        80        0      20   \n",
      "4  NP_114116.3  mdXP_059537613.1   0.691     266        80        0      20   \n",
      "\n",
      "   qend  sstart  send         evalue  bitscore  \n",
      "0   278       1   266  3.798000e-119       381  \n",
      "1   278       1   266  3.798000e-119       381  \n",
      "2   278       1   266  3.798000e-119       381  \n",
      "3   278       1   266  3.798000e-119       381  \n",
      "4   278       1   266  3.798000e-119       381  \n",
      "mldf head:\n",
      "        qseqid            sseqid  pident  length  mismatch  gapopen  qstart  \\\n",
      "0  NP_005384.2  mlXP_023608751.1   0.748    1901       420        0       9   \n",
      "1  NP_005752.1  mlXP_006096153.1   0.913    1172       101        0     402   \n",
      "2  NP_055918.2  mlXP_006083996.1   0.933    1816       121        0     121   \n",
      "3  NP_067048.4  mlXP_023619030.1   0.375      64        38        0     147   \n",
      "4  NP_067048.4  mlXP_023619031.1   0.375      64        38        0     147   \n",
      "\n",
      "   qend  sstart  send    evalue  bitscore  \n",
      "0  1909       4  1670  0.000000      2864  \n",
      "1  1568       1  1172  0.000000      2203  \n",
      "2  1925       1  1816  0.000000      3517  \n",
      "3   208     457   520  0.000327        43  \n",
      "4   208     457   520  0.000327        43  \n",
      "mmdf head:\n",
      "        qseqid            sseqid  pident  length  mismatch  gapopen  qstart  \\\n",
      "0  NP_001147.1  mmXP_036192976.1   0.905     466        44        0       1   \n",
      "1  NP_004025.1  mmXP_036192972.1   0.901     488        48        0       1   \n",
      "2  NP_004025.1  mmXP_036192974.1   0.901     488        48        0       1   \n",
      "3  NP_004025.1  mmXP_036192975.1   0.901     488        48        0       1   \n",
      "4  NP_922941.1  mmXP_036157263.1   0.761     168        40        0       1   \n",
      "\n",
      "   qend  sstart  send         evalue  bitscore  \n",
      "0   466       1   462  2.024000e-291       889  \n",
      "1   488       1   484  4.162000e-303       924  \n",
      "2   488       1   484  4.162000e-303       924  \n",
      "3   488       1   484  4.162000e-303       924  \n",
      "4   168       1   168   1.753000e-83       272  \n",
      "modf head:\n",
      "           qseqid            sseqid  pident  length  mismatch  gapopen  \\\n",
      "0     NP_006335.2  moXP_036124594.1   0.583     288       118        0   \n",
      "1     NP_003656.2  moXP_036112711.1   0.761     298        71        0   \n",
      "2  XP_005265439.1  moXP_036123037.1   0.976     754        18        0   \n",
      "3     NP_922938.1  moXP_036108798.1   0.680     247        78        0   \n",
      "4     NP_922939.1  moXP_036108804.1   0.629     189        69        0   \n",
      "\n",
      "   qstart  qend  sstart  send         evalue  bitscore  \n",
      "0       1   288       1   284  1.206000e-117       377  \n",
      "1       1   298       1   297  3.954000e-160       500  \n",
      "2       1   754       1   754   0.000000e+00      1577  \n",
      "3       1   247       1   246  4.435000e-107       344  \n",
      "4       1   189       1   188   9.222000e-71       236  \n",
      "padf head:\n",
      "           qseqid            sseqid  pident  length  mismatch  gapopen  \\\n",
      "0     NP_114116.3  paXP_006913566.1   0.687     266        81        0   \n",
      "1  XP_005261382.1  paXP_006913566.1   0.687     266        81        0   \n",
      "2  XP_006724188.1  paXP_006913566.1   0.687     266        81        0   \n",
      "3  NP_001128642.1  paXP_006919049.1   0.969     296         9        0   \n",
      "4     NP_997302.2  paXP_006914271.1   0.797     252        51        0   \n",
      "\n",
      "   qstart  qend  sstart  send         evalue  bitscore  \n",
      "0      20   278       1   266  2.850000e-117       375  \n",
      "1       1   259       1   266  1.218000e-117       375  \n",
      "2       1   259       1   266  1.218000e-117       375  \n",
      "3       1   296       1   296  2.805000e-204       627  \n",
      "4       1   252       1   251  9.078000e-135       424  \n",
      "pddf head:\n",
      "        qseqid            sseqid  pident  length  mismatch  gapopen  qstart  \\\n",
      "0  NP_004475.1  pdXP_028378282.1   0.960     580        23        0       1   \n",
      "1  NP_001439.2  pdXP_028378229.1   0.931     556        38        0       1   \n",
      "2  NP_004457.1  pdXP_028382383.1   0.849     572        86        0       1   \n",
      "3  NP_005699.1  pdXP_028382407.1   0.980     555        11        0       1   \n",
      "4  NP_037504.1  pdXP_035887276.1   0.907     184        17        0       1   \n",
      "\n",
      "   qend  sstart  send         evalue  bitscore  \n",
      "0   580       1   580   0.000000e+00      1169  \n",
      "1   556       1   556   0.000000e+00      1087  \n",
      "2   572       2   573   0.000000e+00      1041  \n",
      "3   555       1   555   0.000000e+00      1127  \n",
      "4   184       1   184  9.378000e-112       354  \n",
      "pgdf head:\n",
      "           qseqid            sseqid  pident  length  mismatch  gapopen  \\\n",
      "0  XP_006721729.1  pgXP_039715728.1   0.806     288        55        0   \n",
      "1     NP_114114.2  pgXP_039733064.1   0.915     318        27        0   \n",
      "2     NP_112207.1  pgXP_039698644.1   0.979     242         5        0   \n",
      "3     NP_114115.2  pgXP_039725219.1   0.935     328        21        0   \n",
      "4  NP_001265360.1  pgXP_039722584.1   0.975     243         6        0   \n",
      "\n",
      "   qstart  qend  sstart  send         evalue  bitscore  \n",
      "0       4   291     119   405  1.099000e-155       487  \n",
      "1      13   330       9   326  1.612000e-205       633  \n",
      "2       5   246       4   245  1.976000e-169       524  \n",
      "3       1   328       1   324  4.112000e-203       626  \n",
      "4       1   243       1   243  1.022000e-166       516  \n",
      "phdf head:\n",
      "           qseqid            sseqid  pident  length  mismatch  gapopen  \\\n",
      "0     NP_000482.3  phXP_045714773.1   0.821     251        45        0   \n",
      "1     NP_002072.2  phXP_045701530.1   0.852     561        82        0   \n",
      "2  XP_005253381.1  phXP_045695676.1   0.578     265       111        0   \n",
      "3  NP_001156729.1  phXP_045701399.1   0.869    1891       247        0   \n",
      "4  NP_001156729.1  phXP_045701400.1   0.869    1891       247        0   \n",
      "\n",
      "   qstart  qend  sstart  send         evalue  bitscore  \n",
      "0       2   252     696   946  1.511000e-140       441  \n",
      "1       1   558       1   561   0.000000e+00       993  \n",
      "2       1   264       1   265   2.474000e-97       317  \n",
      "3      42  1932       1  1890   0.000000e+00      3440  \n",
      "4      42  1932       1  1890   0.000000e+00      3440  \n",
      "pkdf head:\n",
      "           qseqid            sseqid  pident  length  mismatch  gapopen  \\\n",
      "0     NP_705870.1  pkXP_036299029.1   0.956    1017        45        0   \n",
      "1     NP_705870.1  pkXP_036299030.1   0.956    1017        45        0   \n",
      "2     NP_705871.1  pkXP_036298970.1   0.954    1073        49        0   \n",
      "3     NP_705871.1  pkXP_045438792.1   0.954    1073        49        0   \n",
      "4  XP_005254744.1  pkXP_036298970.1   0.954    1073        49        0   \n",
      "\n",
      "   qstart  qend  sstart  send  evalue  bitscore  \n",
      "0       1  1017       1  1017     0.0      2065  \n",
      "1       1  1017       1  1017     0.0      2065  \n",
      "2       1  1073       1  1073     0.0      2169  \n",
      "3       1  1073       1  1073     0.0      2169  \n",
      "4       1  1073       1  1073     0.0      2169  \n",
      "pndf head:\n",
      "           qseqid          sseqid  pident  length  mismatch  gapopen  qstart  \\\n",
      "0     NP_689504.2  pnCAK6444061.1   0.355     281       180        0      72   \n",
      "1  NP_001265360.1  pnCAK6448683.1   0.843     243        37        0       1   \n",
      "2     NP_004177.3  pnCAK6435885.1   0.951     785        38        0       1   \n",
      "3  XP_005265438.1  pnCAK6435885.1   0.951     785        38        0       1   \n",
      "4     NP_064548.1  pnCAK6435516.1   0.864     782       105        0       1   \n",
      "\n",
      "   qend  sstart  send         evalue  bitscore  \n",
      "0   351     585   865   9.430000e-33       132  \n",
      "1   243       1   237  1.257000e-142       445  \n",
      "2   785       1   784   0.000000e+00      1589  \n",
      "3   785       1   784   0.000000e+00      1589  \n",
      "4   782       1   770   0.000000e+00      1424  \n",
      "pvdf head:\n",
      "           qseqid            sseqid  pident  length  mismatch  gapopen  \\\n",
      "0  NP_001138365.1  pvXP_023380689.1   0.661     136        46        0   \n",
      "1     NP_000482.3  pvXP_011355853.1   0.850     248        37        0   \n",
      "2     NP_997302.2  pvXP_011375286.1   0.793     252        52        0   \n",
      "3     NP_848635.2  pvXP_011360121.1   0.867     332        44        0   \n",
      "4  NP_001138365.1  pvXP_023380689.1   0.661     136        46        0   \n",
      "\n",
      "   qstart  qend  sstart  send         evalue  bitscore  \n",
      "0     116   251      58   193   1.152000e-59       208  \n",
      "1       3   250       1   248  7.341000e-147       459  \n",
      "2       1   252       1   250  5.225000e-133       419  \n",
      "3       1   332       1   330  1.279000e-206       636  \n",
      "4     116   251      58   193   1.152000e-59       208  \n",
      "radf head:\n",
      "           qseqid            sseqid  pident  length  mismatch  gapopen  \\\n",
      "0     NP_872425.2  raXP_036087255.1   0.842     445        70        0   \n",
      "1     NP_872425.2  raXP_016020000.2   0.842     445        70        0   \n",
      "2     NP_872425.2  raXP_016020001.2   0.842     445        70        0   \n",
      "3  XP_005255991.1  raXP_036087255.1   0.842     445        70        0   \n",
      "4  XP_005255991.1  raXP_016020000.2   0.842     445        70        0   \n",
      "\n",
      "   qstart  qend  sstart  send         evalue  bitscore  \n",
      "0       1   444       1   445  1.161000e-269       825  \n",
      "1       1   444       1   445  1.161000e-269       825  \n",
      "2       1   444       1   445  1.161000e-269       825  \n",
      "3       1   444       1   445  1.161000e-269       825  \n",
      "4       1   444       1   445  1.161000e-269       825  \n",
      "rfdf head:\n",
      "           qseqid            sseqid  pident  length  mismatch  gapopen  \\\n",
      "0  XP_005253524.1  rfXP_032972071.1   0.725     244        67        0   \n",
      "1  NP_001171175.1  rfXP_032979790.1   0.840     715       114        0   \n",
      "2  NP_001171175.1  rfXP_032979791.1   0.840     715       114        0   \n",
      "3  XP_006716792.1  rfXP_032979790.1   0.840     715       114        0   \n",
      "4  XP_006716792.1  rfXP_032979791.1   0.840     715       114        0   \n",
      "\n",
      "   qstart  qend  sstart  send         evalue  bitscore  \n",
      "0       1   244       1   243  6.762000e-113       361  \n",
      "1       1   715       1   715   0.000000e+00      1287  \n",
      "2       1   715       1   715   0.000000e+00      1287  \n",
      "3       1   715       1   715   0.000000e+00      1287  \n",
      "4       1   715       1   715   0.000000e+00      1287  \n",
      "sbdf head:\n",
      "           qseqid            sseqid  pident  length  mismatch  gapopen  \\\n",
      "0  XP_006715792.1  sbXP_066129620.1   0.857     828       118        0   \n",
      "1  XP_006715792.1  sbXP_066129621.1   0.857     828       118        0   \n",
      "2  XP_006715792.1  sbXP_066129622.1   0.857     828       118        0   \n",
      "3     NP_443138.2  sbXP_066114975.1   0.961     824        32        0   \n",
      "4     NP_443138.2  sbXP_066115007.1   0.961     824        32        0   \n",
      "\n",
      "   qstart  qend  sstart  send  evalue  bitscore  \n",
      "0       1   828      48   873     0.0      1454  \n",
      "1       1   828      48   873     0.0      1454  \n",
      "2       1   828      48   873     0.0      1454  \n",
      "3       1   820       1   824     0.0      1646  \n",
      "4       1   820       1   824     0.0      1646  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Define columns\n",
    "columns = [\"qseqid\", \"sseqid\", \"pident\", \"length\", \"mismatch\", \"gapopen\",  \n",
    "           \"qstart\", \"qend\", \"sstart\", \"send\", \"evalue\", \"bitscore\"]\n",
    "\n",
    "# Dictionary to store DataFrames\n",
    "dfs = {}\n",
    "\n",
    "# Print to debug which files are being processed\n",
    "filepaths = glob.glob(\"ecmaffil/*.tab\")\n",
    "print(\"Found files:\", filepaths)  # Debug statement\n",
    "\n",
    "# Load each .tab file from the 'rbhresults' directory and store it in the dictionary\n",
    "for filepath in filepaths:\n",
    "    # Extract the prefix from the filename (e.g., \"aj\" from \"rbhresults/ajrbh.tab\")\n",
    "    prefix = os.path.basename(filepath)[:2]\n",
    "    # Load the file into a DataFrame\n",
    "    df = pd.read_csv(filepath, sep='\\t', names=columns)\n",
    "    # Store the DataFrame in the dictionary with the prefix as the key\n",
    "    dfs[f\"{prefix}df\"] = df\n",
    "\n",
    "# Print out the keys of the dictionary to verify all DataFrames were loaded\n",
    "print(\"DataFrames loaded:\", list(dfs.keys()))  # Debug statement\n",
    "\n",
    "# Example: Print the head of each DataFrame to verify\n",
    "for name, dataframe in dfs.items():\n",
    "    print(f\"{name} head:\")\n",
    "    print(dataframe.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DataFrames in the global namespace using the prefix as variable names\n",
    "for prefix, df in dfs.items():\n",
    "    globals()[prefix] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qseqid</th>\n",
       "      <th>sseqid</th>\n",
       "      <th>pident</th>\n",
       "      <th>length</th>\n",
       "      <th>mismatch</th>\n",
       "      <th>gapopen</th>\n",
       "      <th>qstart</th>\n",
       "      <th>qend</th>\n",
       "      <th>sstart</th>\n",
       "      <th>send</th>\n",
       "      <th>evalue</th>\n",
       "      <th>bitscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XP_006715792.1</td>\n",
       "      <td>sbXP_066129620.1</td>\n",
       "      <td>0.857</td>\n",
       "      <td>828</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>828</td>\n",
       "      <td>48</td>\n",
       "      <td>873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XP_006715792.1</td>\n",
       "      <td>sbXP_066129621.1</td>\n",
       "      <td>0.857</td>\n",
       "      <td>828</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>828</td>\n",
       "      <td>48</td>\n",
       "      <td>873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XP_006715792.1</td>\n",
       "      <td>sbXP_066129622.1</td>\n",
       "      <td>0.857</td>\n",
       "      <td>828</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>828</td>\n",
       "      <td>48</td>\n",
       "      <td>873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NP_443138.2</td>\n",
       "      <td>sbXP_066114975.1</td>\n",
       "      <td>0.961</td>\n",
       "      <td>824</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>820</td>\n",
       "      <td>1</td>\n",
       "      <td>824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NP_443138.2</td>\n",
       "      <td>sbXP_066115007.1</td>\n",
       "      <td>0.961</td>\n",
       "      <td>824</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>820</td>\n",
       "      <td>1</td>\n",
       "      <td>824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           qseqid            sseqid  pident  length  mismatch  gapopen  \\\n",
       "0  XP_006715792.1  sbXP_066129620.1   0.857     828       118        0   \n",
       "1  XP_006715792.1  sbXP_066129621.1   0.857     828       118        0   \n",
       "2  XP_006715792.1  sbXP_066129622.1   0.857     828       118        0   \n",
       "3     NP_443138.2  sbXP_066114975.1   0.961     824        32        0   \n",
       "4     NP_443138.2  sbXP_066115007.1   0.961     824        32        0   \n",
       "\n",
       "   qstart  qend  sstart  send  evalue  bitscore  \n",
       "0       1   828      48   873     0.0      1454  \n",
       "1       1   828      48   873     0.0      1454  \n",
       "2       1   828      48   873     0.0      1454  \n",
       "3       1   820       1   824     0.0      1646  \n",
       "4       1   820       1   824     0.0      1646  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All bat protein sequences written to rbh_all_bats_ecmaffil.fasta\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "bat_fasta_file = \"realmergedprots.faa\"  # This is the merged bat proteome file\n",
    "output_file = \"rbh_all_bats_ecmaffil.fasta\"\n",
    "\n",
    "# Load bat sequences with duplicates handled\n",
    "def load_fasta_with_duplicates(fasta_file):\n",
    "    sequences = {}\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        if record.id not in sequences:\n",
    "            sequences[record.id] = record\n",
    "        else:\n",
    "            print(f\"Duplicate ID found: {record.id}, ignoring this entry.\")\n",
    "    return sequences\n",
    "\n",
    "# Load the bat sequences\n",
    "bat_sequences = load_fasta_with_duplicates(bat_fasta_file)\n",
    "\n",
    "# List of DataFrames (replace 'dfs' with your dictionary or variable holding the DataFrames)\n",
    "dataframe_list = [ajdf, drdf, efdf, endf, mbdf, mddf, mldf, mmdf, modf, padf, pddf, pgdf, phdf, pkdf, pndf, pvdf, radf, rfdf, sbdf]\n",
    "\n",
    "# Open the output FASTA file\n",
    "with open(output_file, \"w\") as output_fasta:\n",
    "    # Loop over each DataFrame\n",
    "    for df in dataframe_list:\n",
    "        # Process each sseqid in the DataFrame\n",
    "        for _, row in df.iterrows():\n",
    "            sseqid_full = row[\"sseqid\"]  # Keep the full ID with prefix\n",
    "            \n",
    "            # Check if the sseqid_full is in the bat sequences\n",
    "            if sseqid_full in bat_sequences:\n",
    "                sseq = bat_sequences[sseqid_full].seq\n",
    "                sdesc = bat_sequences[sseqid_full].description\n",
    "                \n",
    "                # Determine the ID source based on the prefix if needed\n",
    "                prefix = sseqid_full[:2]\n",
    "                if prefix == \"pn\" or prefix == 'en':\n",
    "                    id_source = \"GenBank\"\n",
    "                else:\n",
    "                    id_source = \"RefSeq\"\n",
    "                \n",
    "                # Write the bat protein sequence to the output file\n",
    "                output_fasta.write(f\">{sseqid_full} {sdesc} [{id_source}]\\n{sseq}\\n\")\n",
    "            else:\n",
    "                print(f\"SseqID {sseqid_full} not found in bat proteome.\")\n",
    "\n",
    "print(f\"All bat protein sequences written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     representative                                             member\n",
      "0  ajXP_036981807.2  [ajXP_036981807.2, ajXP_036981816.2, ajXP_0369...\n",
      "1  ajXP_036981962.2  [ajXP_036981962.2, pdXP_028358868.1, pdXP_0358...\n",
      "2  ajXP_036983531.2                                 [ajXP_036983531.2]\n",
      "3  ajXP_036984287.2               [ajXP_036984287.2, ajXP_036984287.2]\n",
      "4  ajXP_036984952.1  [ajXP_036984952.1, pdXP_028374642.2, rfXP_0329...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "rbh_df = pd.read_csv(\"rbhecmaffilclustershighid.tsv\", sep=\"\\t\", header=None, names=[\"representative\", \"member\"])\n",
    "\n",
    "aggregated_df = rbh_df.groupby(\"representative\")[\"member\"].apply(list).reset_index()\n",
    "\n",
    "print(aggregated_df.head())\n",
    "\n",
    "aggregated_df.to_csv(\"aggregated_ECMAFFIL_clusters.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\anaconda\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\anaconda\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/11.0 MB 1.5 MB/s eta 0:00:08\n",
      "    --------------------------------------- 0.3/11.0 MB 2.0 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.4/11.0 MB 2.3 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.5/11.0 MB 2.2 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.7/11.0 MB 2.6 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.8/11.0 MB 2.6 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.0/11.0 MB 2.8 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.1/11.0 MB 2.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 2.9 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 2.8 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 2.8 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 2.8 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 2.8 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 2.8 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 2.3 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.7/11.0 MB 2.2 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.7/11.0 MB 2.2 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.8/11.0 MB 2.1 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.8/11.0 MB 2.1 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.8/11.0 MB 2.1 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.8/11.0 MB 2.1 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.9/11.0 MB 1.8 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.9/11.0 MB 1.8 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.0/11.0 MB 1.8 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.1/11.0 MB 1.8 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.1/11.0 MB 1.8 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.1/11.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.2/11.0 MB 1.7 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.3/11.0 MB 1.7 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.3/11.0 MB 1.6 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.3/11.0 MB 1.6 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.3/11.0 MB 1.6 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.4/11.0 MB 1.6 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.4/11.0 MB 1.5 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.4/11.0 MB 1.5 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.4/11.0 MB 1.5 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.5/11.0 MB 1.5 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.5/11.0 MB 1.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.5/11.0 MB 1.4 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.5/11.0 MB 1.4 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.6/11.0 MB 1.4 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.6/11.0 MB 1.3 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.6/11.0 MB 1.3 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.7/11.0 MB 1.3 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.7/11.0 MB 1.3 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.7/11.0 MB 1.3 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.7/11.0 MB 1.3 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 1.3 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 3.0/11.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 3.0/11.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 3.0/11.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 3.0/11.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 3.2/11.0 MB 1.1 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 3.2/11.0 MB 1.1 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 3.2/11.0 MB 1.1 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 3.2/11.0 MB 1.1 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 3.3/11.0 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.3/11.0 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.3/11.0 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.4/11.0 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.4/11.0 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.4/11.0 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.5/11.0 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.5/11.0 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.5/11.0 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 3.6/11.0 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 3.6/11.0 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 3.7/11.0 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 3.7/11.0 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 3.7/11.0 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 3.8/11.0 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 3.8/11.0 MB 1.0 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 3.9/11.0 MB 1.0 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 3.9/11.0 MB 1.0 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 3.9/11.0 MB 1.0 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 4.0/11.0 MB 1.0 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 4.0/11.0 MB 1.0 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 4.1/11.0 MB 1.0 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 4.1/11.0 MB 1.0 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 4.1/11.0 MB 1.0 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 4.1/11.0 MB 999.0 kB/s eta 0:00:07\n",
      "   --------------- ------------------------ 4.2/11.0 MB 999.0 kB/s eta 0:00:07\n",
      "   --------------- ------------------------ 4.2/11.0 MB 992.7 kB/s eta 0:00:07\n",
      "   --------------- ------------------------ 4.2/11.0 MB 989.0 kB/s eta 0:00:07\n",
      "   --------------- ------------------------ 4.3/11.0 MB 985.5 kB/s eta 0:00:07\n",
      "   --------------- ------------------------ 4.3/11.0 MB 984.3 kB/s eta 0:00:07\n",
      "   --------------- ------------------------ 4.3/11.0 MB 983.1 kB/s eta 0:00:07\n",
      "   --------------- ------------------------ 4.4/11.0 MB 981.9 kB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 4.4/11.0 MB 980.8 kB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 981.9 kB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 983.0 kB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 4.6/11.0 MB 983.0 kB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 4.6/11.0 MB 985.3 kB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 984.2 kB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 985.2 kB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 4.8/11.0 MB 982.0 kB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 4.8/11.0 MB 986.3 kB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 4.9/11.0 MB 987.3 kB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 4.9/11.0 MB 988.2 kB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 4.9/11.0 MB 988.2 kB/s eta 0:00:07\n",
      "   ------------------ --------------------- 5.0/11.0 MB 986.1 kB/s eta 0:00:07\n",
      "   ------------------ --------------------- 5.0/11.0 MB 986.1 kB/s eta 0:00:07\n",
      "   ------------------ --------------------- 5.1/11.0 MB 986.0 kB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.1/11.0 MB 987.1 kB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.2/11.0 MB 990.8 kB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.2/11.0 MB 987.8 kB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.3/11.0 MB 991.7 kB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.3/11.0 MB 991.7 kB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.4/11.0 MB 992.6 kB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.4/11.0 MB 997.1 kB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.5/11.0 MB 996.1 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.6/11.0 MB 1.0 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.6/11.0 MB 1.0 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.7/11.0 MB 1.0 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.7/11.0 MB 1.0 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 5.8/11.0 MB 1.0 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 5.8/11.0 MB 1.0 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 5.9/11.0 MB 1.0 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 6.0/11.0 MB 1.0 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.0/11.0 MB 1.0 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.1/11.0 MB 1.0 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.1/11.0 MB 1.0 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.2/11.0 MB 1.0 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 1.0 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 1.0 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 6.4/11.0 MB 1.0 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 6.4/11.0 MB 1.0 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 6.6/11.0 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 6.7/11.0 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 6.7/11.0 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 6.8/11.0 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 6.9/11.0 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 6.9/11.0 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 7.0/11.0 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 7.1/11.0 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 7.1/11.0 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 7.2/11.0 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 7.3/11.0 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 7.3/11.0 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 7.4/11.0 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 7.5/11.0 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 7.6/11.0 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 7.7/11.0 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 7.7/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.8/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.9/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.9/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.0/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.0/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.0/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.1/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.1/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.2/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.2/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.3/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.3/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.4/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.4/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.4/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.5/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.5/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.6/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.6/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.6/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.7/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.7/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.8/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 8.8/11.0 MB 1.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 8.9/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 8.9/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.0/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.0/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.1/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.1/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.2/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.2/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.3/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.3/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.3/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.5/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.5/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.6/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 9.6/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 9.8/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 9.8/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 9.9/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 9.9/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 9.9/11.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.0/11.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.0/11.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.0/11.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.1/11.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.1/11.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.2/11.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.2/11.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.2/11.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.2/11.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.3/11.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.3/11.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.4/11.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.4/11.0 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.4/11.0 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.5/11.0 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.5/11.0 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.6/11.0 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.6/11.0 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.6/11.0 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.0 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.8/11.0 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.8/11.0 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.8/11.0 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.0 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.0 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 1.0 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 41.0/301.8 kB 991.0 kB/s eta 0:00:01\n",
      "   ------------ --------------------------- 92.2/301.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 122.9/301.8 kB 1.0 MB/s eta 0:00:01\n",
      "   --------------------- ---------------- 174.1/301.8 kB 952.6 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 204.8/301.8 kB 958.4 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 235.5/301.8 kB 901.1 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 256.0/301.8 kB 874.6 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 256.0/301.8 kB 874.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- 301.8/301.8 kB 747.6 kB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score based on pident: 0.1308272679803392\n",
      "Silhouette Score based on evalue: 0.09561641401269973\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Load the alignment data\n",
    "alignment_df = pd.read_csv(\"ecmaffil_cluster_aligns.tsv\", sep=\"\\t\", \n",
    "                           names=[\"query\", \"target\", \"evalue\", \"pident\", \"alnlen\", \"qstart\", \"qend\", \"tstart\", \"tend\"])\n",
    "\n",
    "# Load clustering information with representative and members\n",
    "aggregated_df = pd.read_csv(\"aggregated_ECMAFFIL_clusters.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Filter clusters with more than 1 unique protein and at least 2 different species\n",
    "filtered_clusters = []\n",
    "for _, row in aggregated_df.iterrows():\n",
    "    members = row[\"member\"].strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
    "    unique_prefixes = set(m[:2] for m in members)  # Get unique species prefixes\n",
    "\n",
    "    if len(members) > 1 and len(unique_prefixes) > 1:\n",
    "        filtered_clusters.append({\"representative\": row[\"representative\"], \"members\": members})\n",
    "\n",
    "# Create a combined list of all proteins across clusters\n",
    "all_proteins = {protein for cluster in filtered_clusters for protein in cluster[\"members\"]}\n",
    "protein_index = {protein: idx for idx, protein in enumerate(all_proteins)}\n",
    "num_proteins = len(all_proteins)\n",
    "\n",
    "# Initialize distance matrices for pident and evalue\n",
    "pident_matrix = np.zeros((num_proteins, num_proteins))\n",
    "evalue_matrix = np.zeros((num_proteins, num_proteins))\n",
    "\n",
    "# Populate matrices based on pairwise alignments\n",
    "for _, row in alignment_df.iterrows():\n",
    "    if row[\"query\"] in protein_index and row[\"target\"] in protein_index:\n",
    "        i, j = protein_index[row[\"query\"]], protein_index[row[\"target\"]]\n",
    "        pident_matrix[i, j] = row[\"pident\"] / 100  # Convert to fraction\n",
    "        pident_matrix[j, i] = row[\"pident\"] / 100\n",
    "        evalue_matrix[i, j] = -np.log(row[\"evalue\"] + 1e-300)\n",
    "        evalue_matrix[j, i] = -np.log(row[\"evalue\"] + 1e-300)\n",
    "\n",
    "# Convert similarity to distance for silhouette calculation\n",
    "pident_distance = 1 - pident_matrix\n",
    "evalue_distance = 1 - (evalue_matrix / np.max(evalue_matrix))\n",
    "\n",
    "# Create labels based on cluster membership\n",
    "labels = np.full(num_proteins, -1)  # Initialize with -1 for unassigned\n",
    "for cluster_id, cluster in enumerate(filtered_clusters):\n",
    "    for member in cluster[\"members\"]:\n",
    "        if member in protein_index:\n",
    "            labels[protein_index[member]] = cluster_id  # Assign cluster ID as label\n",
    "\n",
    "# Filter out unassigned proteins\n",
    "valid_indices = labels != -1\n",
    "# Convert similarity to distance for silhouette calculation\n",
    "pident_distance = 1 - pident_matrix\n",
    "evalue_distance = 1 - (evalue_matrix / np.max(evalue_matrix))  # Normalize evalue distances\n",
    "\n",
    "# Set diagonal to zero for both distance matrices\n",
    "np.fill_diagonal(pident_distance, 0)\n",
    "np.fill_diagonal(evalue_distance, 0)\n",
    "\n",
    "# Assign labels for silhouette calculation\n",
    "labels = labels[valid_indices]  # Ensure labels are only for valid indices\n",
    "\n",
    "# Calculate silhouette scores for both pident and evalue distances\n",
    "pident_silhouette_score = silhouette_score(pident_distance, labels, metric=\"precomputed\")\n",
    "evalue_silhouette_score = silhouette_score(evalue_distance, labels, metric=\"precomputed\")\n",
    "\n",
    "# Display results\n",
    "print(\"Silhouette Score based on pident:\", pident_silhouette_score)\n",
    "print(\"Silhouette Score based on evalue:\", evalue_silhouette_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pident_distance min/max: 0.0 1.0\n",
      "evalue_distance min/max: 0.0 1.0\n",
      "Silhouette Score based on pident: 0.1308272679803392\n",
      "Silhouette Score based on evalue: 0.09561641401269973\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Load the alignment data\n",
    "alignment_df = pd.read_csv(\"ecmaffil_cluster_aligns.tsv\", sep=\"\\t\", \n",
    "                           names=[\"query\", \"target\", \"evalue\", \"pident\", \"alnlen\", \"qstart\", \"qend\", \"tstart\", \"tend\"])\n",
    "\n",
    "# Load clustering information with representative and members\n",
    "aggregated_df = pd.read_csv(\"aggregated_ECMAFFIL_clusters.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Filter clusters with more than 1 unique protein and at least 2 different species\n",
    "filtered_clusters = []\n",
    "for _, row in aggregated_df.iterrows():\n",
    "    members = row[\"member\"].strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
    "    unique_prefixes = set(m[:2] for m in members)  # Get unique species prefixes\n",
    "\n",
    "    if len(members) > 1 and len(unique_prefixes) > 1:\n",
    "        filtered_clusters.append({\"representative\": row[\"representative\"], \"members\": members})\n",
    "\n",
    "# Create a combined list of all proteins across clusters\n",
    "all_proteins = {protein for cluster in filtered_clusters for protein in cluster[\"members\"]}\n",
    "protein_index = {protein: idx for idx, protein in enumerate(all_proteins)}\n",
    "num_proteins = len(all_proteins)\n",
    "\n",
    "# Initialize distance matrices for pident and evalue\n",
    "pident_matrix = np.zeros((num_proteins, num_proteins))\n",
    "evalue_matrix = np.zeros((num_proteins, num_proteins))\n",
    "\n",
    "# Populate matrices based on pairwise alignments\n",
    "for _, row in alignment_df.iterrows():\n",
    "    if row[\"query\"] in protein_index and row[\"target\"] in protein_index:\n",
    "        i, j = protein_index[row[\"query\"]], protein_index[row[\"target\"]]\n",
    "        pident_matrix[i, j] = row[\"pident\"] / 100  # Convert to fraction\n",
    "        pident_matrix[j, i] = row[\"pident\"] / 100\n",
    "        evalue_matrix[i, j] = -np.log(row[\"evalue\"] + 1e-300)\n",
    "        evalue_matrix[j, i] = -np.log(row[\"evalue\"] + 1e-300)\n",
    "\n",
    "# Symmetry checks\n",
    "assert np.allclose(pident_matrix, pident_matrix.T), \"pident_matrix is not symmetric\"\n",
    "assert np.allclose(evalue_matrix, evalue_matrix.T), \"evalue_matrix is not symmetric\"\n",
    "\n",
    "# Convert similarity to distance for silhouette calculation\n",
    "pident_distance = 1 - pident_matrix\n",
    "evalue_distance = 1 - (evalue_matrix / np.max(evalue_matrix))\n",
    "\n",
    "# Ensure the diagonal is zero\n",
    "np.fill_diagonal(pident_distance, 0)\n",
    "np.fill_diagonal(evalue_distance, 0)\n",
    "\n",
    "# Check distance matrix ranges\n",
    "print(\"pident_distance min/max:\", pident_distance.min(), pident_distance.max())\n",
    "print(\"evalue_distance min/max:\", evalue_distance.min(), evalue_distance.max())\n",
    "\n",
    "# Create labels based on cluster membership\n",
    "labels = np.full(num_proteins, -1)  # Initialize with -1 for unassigned\n",
    "for cluster_id, cluster in enumerate(filtered_clusters):\n",
    "    for member in cluster[\"members\"]:\n",
    "        if member in protein_index:\n",
    "            labels[protein_index[member]] = cluster_id  # Assign cluster ID as label\n",
    "\n",
    "# Filter out unassigned proteins only once\n",
    "valid_indices = labels != -1\n",
    "pident_distance = pident_distance[valid_indices][:, valid_indices]\n",
    "evalue_distance = evalue_distance[valid_indices][:, valid_indices]\n",
    "labels = labels[valid_indices]\n",
    "\n",
    "# Re-check diagonal for zero values\n",
    "np.fill_diagonal(pident_distance, 0)\n",
    "np.fill_diagonal(evalue_distance, 0)\n",
    "\n",
    "# Calculate silhouette scores for both pident and evalue distances\n",
    "pident_silhouette_score = silhouette_score(pident_distance, labels, metric=\"precomputed\")\n",
    "evalue_silhouette_score = silhouette_score(evalue_distance, labels, metric=\"precomputed\")\n",
    "\n",
    "# Display results\n",
    "print(\"Silhouette Score based on pident:\", pident_silhouette_score)\n",
    "print(\"Silhouette Score based on evalue:\", evalue_silhouette_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Silhouette Score based on pident: 0.1308272679803392\n",
      "Overall Silhouette Score based on evalue: 0.09561641401269973\n",
      "\n",
      "Average Silhouette Scores for Each Cluster:\n",
      "     cluster  pident_silhouette  evalue_silhouette\n",
      "0          0           0.000000           0.000000\n",
      "1          1           0.157764           0.114562\n",
      "2          2           0.000000           0.000000\n",
      "3          3           0.000000           0.000000\n",
      "4          4           0.476833           0.500000\n",
      "..       ...                ...                ...\n",
      "410      410           0.033798           0.035573\n",
      "411      411           0.000000           0.000000\n",
      "412      412           0.024565           0.032569\n",
      "413      413           0.057053           0.023718\n",
      "414      414           0.008234           0.005363\n",
      "\n",
      "[415 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "# Load the alignment data\n",
    "alignment_df = pd.read_csv(\"ecmaffil_cluster_aligns.tsv\", sep=\"\\t\", \n",
    "                           names=[\"query\", \"target\", \"evalue\", \"pident\", \"alnlen\", \"qstart\", \"qend\", \"tstart\", \"tend\"])\n",
    "\n",
    "# Load clustering information with representative and members\n",
    "aggregated_df = pd.read_csv(\"aggregated_ECMAFFIL_clusters.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Filter clusters with more than 1 unique protein and at least 2 different species\n",
    "filtered_clusters = []\n",
    "for _, row in aggregated_df.iterrows():\n",
    "    members = row[\"member\"].strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
    "    unique_prefixes = set(m[:2] for m in members)  # Get unique species prefixes\n",
    "\n",
    "    if len(members) > 1 and len(unique_prefixes) > 1:\n",
    "        filtered_clusters.append({\"representative\": row[\"representative\"], \"members\": members})\n",
    "\n",
    "# Create a combined list of all proteins across clusters\n",
    "all_proteins = {protein for cluster in filtered_clusters for protein in cluster[\"members\"]}\n",
    "protein_index = {protein: idx for idx, protein in enumerate(all_proteins)}\n",
    "num_proteins = len(all_proteins)\n",
    "\n",
    "# Initialize distance matrices for pident and evalue\n",
    "pident_matrix = np.zeros((num_proteins, num_proteins))\n",
    "evalue_matrix = np.zeros((num_proteins, num_proteins))\n",
    "\n",
    "# Populate matrices based on pairwise alignments\n",
    "for _, row in alignment_df.iterrows():\n",
    "    if row[\"query\"] in protein_index and row[\"target\"] in protein_index:\n",
    "        i, j = protein_index[row[\"query\"]], protein_index[row[\"target\"]]\n",
    "        pident_matrix[i, j] = row[\"pident\"] / 100  # Convert to fraction\n",
    "        pident_matrix[j, i] = row[\"pident\"] / 100\n",
    "        evalue_matrix[i, j] = -np.log(row[\"evalue\"] + 1e-300)\n",
    "        evalue_matrix[j, i] = -np.log(row[\"evalue\"] + 1e-300)\n",
    "\n",
    "# Convert similarity to distance for silhouette calculation\n",
    "pident_distance = 1 - pident_matrix\n",
    "evalue_distance = 1 - (evalue_matrix / np.max(evalue_matrix))\n",
    "\n",
    "# Set diagonal to zero for both distance matrices\n",
    "np.fill_diagonal(pident_distance, 0)\n",
    "np.fill_diagonal(evalue_distance, 0)\n",
    "\n",
    "# Create labels based on cluster membership\n",
    "labels = np.full(num_proteins, -1)  # Initialize with -1 for unassigned\n",
    "for cluster_id, cluster in enumerate(filtered_clusters):\n",
    "    for member in cluster[\"members\"]:\n",
    "        if member in protein_index:\n",
    "            labels[protein_index[member]] = cluster_id  # Assign cluster ID as label\n",
    "\n",
    "# Filter out unassigned proteins\n",
    "valid_indices = labels != -1\n",
    "pident_distance = pident_distance[valid_indices][:, valid_indices]\n",
    "evalue_distance = evalue_distance[valid_indices][:, valid_indices]\n",
    "labels = labels[valid_indices]\n",
    "\n",
    "# Calculate silhouette scores for each sample based on pident and evalue distances\n",
    "pident_silhouette_samples = silhouette_samples(pident_distance, labels, metric=\"precomputed\")\n",
    "evalue_silhouette_samples = silhouette_samples(evalue_distance, labels, metric=\"precomputed\")\n",
    "\n",
    "# Create a DataFrame to store individual silhouette scores with cluster labels\n",
    "silhouette_df = pd.DataFrame({\n",
    "    \"protein\": [protein for protein, index in protein_index.items() if valid_indices[index]],\n",
    "    \"cluster\": labels,\n",
    "    \"pident_silhouette\": pident_silhouette_samples,\n",
    "    \"evalue_silhouette\": evalue_silhouette_samples\n",
    "})\n",
    "\n",
    "# Calculate average silhouette score for each cluster\n",
    "cluster_quality = silhouette_df.groupby(\"cluster\").agg({\n",
    "    \"pident_silhouette\": \"mean\",\n",
    "    \"evalue_silhouette\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "# Display results\n",
    "print(\"Overall Silhouette Score based on pident:\", silhouette_score(pident_distance, labels, metric=\"precomputed\"))\n",
    "print(\"Overall Silhouette Score based on evalue:\", silhouette_score(evalue_distance, labels, metric=\"precomputed\"))\n",
    "print(\"\\nAverage Silhouette Scores for Each Cluster:\")\n",
    "print(cluster_quality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Silhouette Scores for Each Cluster:\n",
      "     cluster  pident_silhouette  evalue_silhouette\n",
      "0          0           0.000000           0.000000\n",
      "1          1           0.157764           0.114562\n",
      "2          2           0.000000           0.000000\n",
      "3          3           0.000000           0.000000\n",
      "4          4           0.476833           0.500000\n",
      "..       ...                ...                ...\n",
      "410      410           0.033798           0.035573\n",
      "411      411           0.000000           0.000000\n",
      "412      412           0.024565           0.032569\n",
      "413      413           0.057053           0.023718\n",
      "414      414           0.008234           0.005363\n",
      "\n",
      "[415 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "# Ensure diagonal elements are zero for silhouette calculation\n",
    "np.fill_diagonal(pident_distance, 0)\n",
    "np.fill_diagonal(evalue_distance, 0)\n",
    "\n",
    "# Filter out unassigned proteins and keep original protein IDs\n",
    "valid_protein_ids = [protein for protein, index in protein_index.items() if valid_indices[index]]\n",
    "labels = labels[valid_indices]\n",
    "pident_distance = pident_distance[valid_indices][:, valid_indices]\n",
    "evalue_distance = evalue_distance[valid_indices][:, valid_indices]\n",
    "\n",
    "# Calculate silhouette scores for each sample based on pident and evalue distances\n",
    "pident_silhouette_samples = silhouette_samples(pident_distance, labels, metric=\"precomputed\")\n",
    "evalue_silhouette_samples = silhouette_samples(evalue_distance, labels, metric=\"precomputed\")\n",
    "\n",
    "# Create a DataFrame to store protein IDs, cluster labels, and silhouette scores\n",
    "silhouette_df = pd.DataFrame({\n",
    "    \"protein\": valid_protein_ids,  # Proper protein IDs instead of indexes\n",
    "    \"cluster\": labels,\n",
    "    \"pident_silhouette\": pident_silhouette_samples,\n",
    "    \"evalue_silhouette\": evalue_silhouette_samples\n",
    "})\n",
    "\n",
    "# Calculate the average silhouette score for each cluster\n",
    "cluster_quality = silhouette_df.groupby(\"cluster\").agg({\n",
    "    \"pident_silhouette\": \"mean\",\n",
    "    \"evalue_silhouette\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "# Display results\n",
    "print(\"Average Silhouette Scores for Each Cluster:\")\n",
    "print(cluster_quality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Silhouette Scores and Members for Each Cluster:\n",
      "     cluster  pident_silhouette  evalue_silhouette  \\\n",
      "0          0           0.000000           0.000000   \n",
      "1          1           0.157764           0.114562   \n",
      "2          2           0.000000           0.000000   \n",
      "3          3           0.000000           0.000000   \n",
      "4          4           0.476833           0.500000   \n",
      "..       ...                ...                ...   \n",
      "410      410           0.033798           0.035573   \n",
      "411      411           0.000000           0.000000   \n",
      "412      412           0.024565           0.032569   \n",
      "413      413           0.057053           0.023718   \n",
      "414      414           0.008234           0.005363   \n",
      "\n",
      "                                       cluster_members  \n",
      "0    [ajXP_036981962.2, pdXP_028358868.1, pdXP_0358...  \n",
      "1    [ajXP_036984952.1, pdXP_028374642.2, rfXP_0329...  \n",
      "2    [ajXP_036986482.1, drXP_045051959.1, pdXP_0283...  \n",
      "3    [ajXP_036995238.2, drXP_024412515.3, phXP_0456...  \n",
      "4    [ajXP_037002255.2, drXP_024422721.2, phXP_0457...  \n",
      "..                                                 ...  \n",
      "410  [sbXP_066103320.1, mbXP_005867005.1, pnCAK6447...  \n",
      "411  [sbXP_066103691.1, pvXP_011358795.1, mmXP_0361...  \n",
      "412  [sbXP_066118416.1, sbXP_066118416.1, sbXP_0661...  \n",
      "413  [sbXP_066133315.1, moXP_036138040.1, mdXP_0595...  \n",
      "414  [sbXP_066133576.1, paXP_015440641.1, pgXP_0397...  \n",
      "\n",
      "[415 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary that maps each cluster ID to the list of members (protein IDs) in that cluster\n",
    "cluster_members_dict = {\n",
    "    cluster_id: cluster[\"members\"]\n",
    "    for cluster_id, cluster in enumerate(filtered_clusters)\n",
    "}\n",
    "\n",
    "# Map each row in silhouette_df to its respective cluster members\n",
    "silhouette_df[\"cluster_members\"] = silhouette_df[\"cluster\"].map(cluster_members_dict)\n",
    "\n",
    "# Group by cluster to get average silhouette scores and list of cluster members\n",
    "cluster_quality = silhouette_df.groupby(\"cluster\").agg({\n",
    "    \"pident_silhouette\": \"mean\",\n",
    "    \"evalue_silhouette\": \"mean\",\n",
    "    \"cluster_members\": \"first\"  # List of members in each cluster\n",
    "}).reset_index()\n",
    "\n",
    "# Display results\n",
    "print(\"Average Silhouette Scores and Members for Each Cluster:\")\n",
    "print(cluster_quality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein</th>\n",
       "      <th>cluster</th>\n",
       "      <th>pident_silhouette</th>\n",
       "      <th>evalue_silhouette</th>\n",
       "      <th>cluster_members</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raXP_016014857.2</td>\n",
       "      <td>392</td>\n",
       "      <td>-0.010123</td>\n",
       "      <td>-0.012346</td>\n",
       "      <td>[raXP_016014858.2, raXP_016014855.2, raXP_0160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phXP_045685890.1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.056235</td>\n",
       "      <td>0.030453</td>\n",
       "      <td>[drXP_024431115.1, phXP_045685890.1, pvXP_0113...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drXP_053779399.1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[drXP_053779400.1, drXP_024416922.2, drXP_0537...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enKAK1329177.1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[efXP_027987183.2, efXP_027987183.2, efXP_0279...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pnCAK6440858.1</td>\n",
       "      <td>320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[pkXP_036301078.1, pnCAK6440858.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pkXP_036265229.1</td>\n",
       "      <td>302</td>\n",
       "      <td>0.969000</td>\n",
       "      <td>0.709389</td>\n",
       "      <td>[pkXP_036265229.1, pnCAK6444114.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>raXP_015995103.1</td>\n",
       "      <td>413</td>\n",
       "      <td>0.029212</td>\n",
       "      <td>0.012315</td>\n",
       "      <td>[sbXP_066133315.1, moXP_036138040.1, mdXP_0595...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pvXP_011363016.1</td>\n",
       "      <td>240</td>\n",
       "      <td>0.089909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>[pgXP_039693759.1, pgXP_039693760.1, pgXP_0396...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>raXP_016018719.1</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.056000</td>\n",
       "      <td>-0.058824</td>\n",
       "      <td>[ajXP_053526079.1, ajXP_053526079.1, pdXP_0283...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pgXP_039697283.1</td>\n",
       "      <td>191</td>\n",
       "      <td>-0.015625</td>\n",
       "      <td>-0.005184</td>\n",
       "      <td>[paXP_024894251.1, paXP_024894252.1, paXP_0248...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            protein  cluster  pident_silhouette  evalue_silhouette  \\\n",
       "0  raXP_016014857.2      392          -0.010123          -0.012346   \n",
       "1  phXP_045685890.1       20           0.056235           0.030453   \n",
       "2  drXP_053779399.1       31           0.000000           0.000000   \n",
       "3    enKAK1329177.1       40           0.000000           0.000000   \n",
       "4    pnCAK6440858.1      320           0.000000           0.000000   \n",
       "5  pkXP_036265229.1      302           0.969000           0.709389   \n",
       "6  raXP_015995103.1      413           0.029212           0.012315   \n",
       "7  pvXP_011363016.1      240           0.089909           0.090909   \n",
       "8  raXP_016018719.1       12          -0.056000          -0.058824   \n",
       "9  pgXP_039697283.1      191          -0.015625          -0.005184   \n",
       "\n",
       "                                     cluster_members  \n",
       "0  [raXP_016014858.2, raXP_016014855.2, raXP_0160...  \n",
       "1  [drXP_024431115.1, phXP_045685890.1, pvXP_0113...  \n",
       "2  [drXP_053779400.1, drXP_024416922.2, drXP_0537...  \n",
       "3  [efXP_027987183.2, efXP_027987183.2, efXP_0279...  \n",
       "4                 [pkXP_036301078.1, pnCAK6440858.1]  \n",
       "5                 [pkXP_036265229.1, pnCAK6444114.1]  \n",
       "6  [sbXP_066133315.1, moXP_036138040.1, mdXP_0595...  \n",
       "7  [pgXP_039693759.1, pgXP_039693760.1, pgXP_0396...  \n",
       "8  [ajXP_053526079.1, ajXP_053526079.1, pdXP_0283...  \n",
       "9  [paXP_024894251.1, paXP_024894252.1, paXP_0248...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longevity-Associated Clusters with at least 3 Proteins, 3 Species, and Silhouette Score > 0.25 for either measure:\n",
      "     cluster                                            members  cluster_size  \\\n",
      "51        51  [efXP_054585911.1, efXP_054585911.1, mmXP_0361...             7   \n",
      "61        61  [mbXP_005859726.1, mbXP_014389815.1, mdXP_0595...             6   \n",
      "64        64  [mbXP_005865977.1, efXP_008151575.2, mmXP_0361...             5   \n",
      "65        65  [mbXP_005869664.1, mbXP_005869664.1, mlXP_0236...             5   \n",
      "67        67  [mbXP_005871410.1, mlXP_006084398.1, mdXP_0595...             3   \n",
      "68        68  [mbXP_005875093.1, mlXP_023614664.1, mmXP_0361...             3   \n",
      "74        74  [mbXP_014386174.1, mdXP_059512329.1, mmXP_0361...             3   \n",
      "88        88  [mdXP_059525433.1, mlXP_006107817.3, mmXP_0361...             3   \n",
      "92        92  [mdXP_059536911.1, mdXP_059536910.1, mlXP_0143...             5   \n",
      "96        96  [mdXP_059549656.1, mlXP_006081093.1, mmXP_0361...             3   \n",
      "102      102  [mdXP_059564734.1, mlXP_006105618.2, mmXP_0361...             4   \n",
      "104      104  [mdXP_059567224.1, mmXP_036151819.1, mmXP_0361...             4   \n",
      "109      109  [mlXP_006084295.1, mbXP_014399301.1, mdXP_0595...             4   \n",
      "110      110  [mlXP_006085874.2, mmXP_036208711.1, mdXP_0595...             3   \n",
      "130      130  [mmXP_036157689.1, mmXP_036157689.1, mlXP_0143...             3   \n",
      "132      132  [mmXP_036158664.1, mdXP_059552641.1, mbXP_0143...             3   \n",
      "137      137  [mmXP_036171276.1, mbXP_005870752.1, mlXP_0061...             4   \n",
      "141      141  [mmXP_036184401.1, mlXP_023614665.1, mbXP_0144...             3   \n",
      "146      146  [mmXP_036193287.1, mlXP_006101042.1, mmXP_0361...             4   \n",
      "151      151  [mmXP_036198115.1, mmXP_036198115.1, mdXP_0595...             5   \n",
      "157      157  [mmXP_036207640.1, mmXP_036207640.1, mlXP_0236...             4   \n",
      "159      159  [mmXP_036207807.1, mlXP_006097347.1, mdXP_0595...             4   \n",
      "197      197  [paXP_024906107.1, pvXP_011377943.1, pvXP_0233...             6   \n",
      "327      327  [pkXP_036313926.1, efXP_008139058.2, pnCAK6443...             4   \n",
      "385      385  [pvXP_023388578.1, pvXP_023388579.1, paXP_0249...             4   \n",
      "\n",
      "     num_species  short_living_percentage  long_living_percentage  \\\n",
      "51             3                 0.000000                0.857143   \n",
      "61             4                 0.000000                1.000000   \n",
      "64             5                 0.000000                0.800000   \n",
      "65             5                 0.000000                0.800000   \n",
      "67             3                 0.000000                1.000000   \n",
      "68             3                 0.000000                1.000000   \n",
      "74             3                 0.000000                1.000000   \n",
      "88             3                 0.000000                1.000000   \n",
      "92             4                 0.000000                1.000000   \n",
      "96             3                 0.000000                1.000000   \n",
      "102            4                 0.000000                1.000000   \n",
      "104            3                 0.000000                1.000000   \n",
      "109            4                 0.000000                1.000000   \n",
      "110            3                 0.000000                1.000000   \n",
      "130            3                 0.000000                1.000000   \n",
      "132            3                 0.000000                1.000000   \n",
      "137            4                 0.000000                1.000000   \n",
      "141            3                 0.000000                1.000000   \n",
      "146            4                 0.000000                1.000000   \n",
      "151            4                 0.000000                1.000000   \n",
      "157            3                 0.000000                1.000000   \n",
      "159            4                 0.000000                1.000000   \n",
      "197            3                 0.833333                0.000000   \n",
      "327            3                 0.750000                0.000000   \n",
      "385            3                 0.750000                0.000000   \n",
      "\n",
      "     average_silhouette_pident  average_silhouette_evalue  \n",
      "51                    0.273429                   0.285714  \n",
      "61                    0.255600                   0.142307  \n",
      "64                    0.285700                   0.217733  \n",
      "65                    0.388700                   0.400000  \n",
      "67                    0.660333                   0.357502  \n",
      "68                    0.658000                   0.277214  \n",
      "74                    0.268641                   0.638889  \n",
      "88                    0.647000                   0.520361  \n",
      "92                    0.383500                   0.231022  \n",
      "96                    0.641000                   0.666667  \n",
      "102                   0.496833                   0.500000  \n",
      "104                   0.490167                   0.339759  \n",
      "109                   0.486500                   0.301040  \n",
      "110                   0.649333                   0.606463  \n",
      "130                   0.322000                   0.166989  \n",
      "132                   0.655333                   0.495027  \n",
      "137                   0.482500                   0.266168  \n",
      "141                   0.661667                   0.248280  \n",
      "146                   0.477000                   0.269386  \n",
      "151                   0.332133                   0.084259  \n",
      "157                   0.485167                   0.500000  \n",
      "159                   0.496833                   0.342946  \n",
      "197                   0.324867                   0.333333  \n",
      "327                   0.482167                   0.297921  \n",
      "385                   0.486000                   0.151397  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Леонид\\AppData\\Local\\Temp\\ipykernel_24188\\3068757847.py:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cluster_longevity = silhouette_df.groupby(\"cluster\").apply(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define longevity-associated prefixes\n",
    "short_living_prefixes = {'sb', 'pn', 'pk', 'mo', 'pd', 'pv', 'pa'}\n",
    "average_living_prefixes = {'en', 'ef', 'ph', 'aj', 'ra', 'pg'}\n",
    "long_living_prefixes = {'mb', 'md', 'ml', 'mm', 'dr', 'rf'}\n",
    "\n",
    "# Function to determine the longevity category based on prefix\n",
    "def get_longevity_category(prefix):\n",
    "    if prefix in short_living_prefixes:\n",
    "        return \"short\"\n",
    "    elif prefix in average_living_prefixes:\n",
    "        return \"average\"\n",
    "    elif prefix in long_living_prefixes:\n",
    "        return \"long\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Add a new column to silhouette_df with the longevity category and species prefix\n",
    "silhouette_df[\"longevity\"] = silhouette_df[\"protein\"].apply(lambda x: get_longevity_category(x[:2]))\n",
    "silhouette_df[\"species_prefix\"] = silhouette_df[\"protein\"].apply(lambda x: x[:2])\n",
    "\n",
    "# Group by cluster and analyze the longevity distribution, species diversity, and silhouette score\n",
    "cluster_longevity = silhouette_df.groupby(\"cluster\").apply(\n",
    "    lambda df: pd.Series({\n",
    "        \"members\": df[\"cluster_members\"].iloc[0],  # List of cluster members\n",
    "        \"cluster_size\": len(df),  # Total number of proteins in the cluster\n",
    "        \"num_species\": df[\"species_prefix\"].nunique(),  # Number of unique species (prefixes)\n",
    "        \"short_living_percentage\": (df[\"longevity\"] == \"short\").mean(),\n",
    "        \"long_living_percentage\": (df[\"longevity\"] == \"long\").mean(),\n",
    "        \"average_silhouette_pident\": df[\"pident_silhouette\"].mean(),\n",
    "        \"average_silhouette_evalue\": df[\"evalue_silhouette\"].mean()\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "# Filter clusters to meet the criteria:\n",
    "# - At least 3 proteins in the cluster\n",
    "# - At least 3 different species (prefixes)\n",
    "# - Either at least 75% short-living or long-living members\n",
    "# - At least one of the silhouette scores is higher than 0.25\n",
    "longevity_associated_clusters = cluster_longevity[\n",
    "    ((cluster_longevity[\"short_living_percentage\"] >= 0.75) | \n",
    "     (cluster_longevity[\"long_living_percentage\"] >= 0.75)) & \n",
    "    (cluster_longevity[\"cluster_size\"] >= 3) & \n",
    "    (cluster_longevity[\"num_species\"] >= 3) &\n",
    "    ((cluster_longevity[\"average_silhouette_pident\"] > 0.25) |\n",
    "     (cluster_longevity[\"average_silhouette_evalue\"] > 0.25))\n",
    "]\n",
    "\n",
    "# Display the longevity-associated clusters with silhouette scores\n",
    "print(\"Longevity-Associated Clusters with at least 3 Proteins, 3 Species, and Silhouette Score > 0.25 for either measure:\")\n",
    "print(longevity_associated_clusters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically no longevity-related clusters. Maybe due to --min-seq-id 0.95 being too high. However, lowering this parameter leads to unspecific clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "longevity_associated_clusters.to_csv(\"longevityecmaffilclust.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>members</th>\n",
       "      <th>cluster_size</th>\n",
       "      <th>num_species</th>\n",
       "      <th>short_living_percentage</th>\n",
       "      <th>long_living_percentage</th>\n",
       "      <th>average_silhouette_pident</th>\n",
       "      <th>average_silhouette_evalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>[efXP_054585911.1, efXP_054585911.1, mmXP_0361...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.273429</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>[mbXP_005859726.1, mbXP_014389815.1, mdXP_0595...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.255600</td>\n",
       "      <td>0.142307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>[mbXP_005865977.1, efXP_008151575.2, mmXP_0361...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.285700</td>\n",
       "      <td>0.217733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>[mbXP_005869664.1, mbXP_005869664.1, mlXP_0236...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.388700</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>[mbXP_005871410.1, mlXP_006084398.1, mdXP_0595...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660333</td>\n",
       "      <td>0.357502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>[mbXP_005875093.1, mlXP_023614664.1, mmXP_0361...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.658000</td>\n",
       "      <td>0.277214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>[mbXP_014386174.1, mdXP_059512329.1, mmXP_0361...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.268641</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>[mdXP_059525433.1, mlXP_006107817.3, mmXP_0361...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.647000</td>\n",
       "      <td>0.520361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>[mdXP_059536911.1, mdXP_059536910.1, mlXP_0143...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.383500</td>\n",
       "      <td>0.231022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>[mdXP_059549656.1, mlXP_006081093.1, mmXP_0361...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.641000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>102</td>\n",
       "      <td>[mdXP_059564734.1, mlXP_006105618.2, mmXP_0361...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.496833</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>104</td>\n",
       "      <td>[mdXP_059567224.1, mmXP_036151819.1, mmXP_0361...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.490167</td>\n",
       "      <td>0.339759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>109</td>\n",
       "      <td>[mlXP_006084295.1, mbXP_014399301.1, mdXP_0595...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.486500</td>\n",
       "      <td>0.301040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>110</td>\n",
       "      <td>[mlXP_006085874.2, mmXP_036208711.1, mdXP_0595...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.649333</td>\n",
       "      <td>0.606463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>130</td>\n",
       "      <td>[mmXP_036157689.1, mmXP_036157689.1, mlXP_0143...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.322000</td>\n",
       "      <td>0.166989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>132</td>\n",
       "      <td>[mmXP_036158664.1, mdXP_059552641.1, mbXP_0143...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.655333</td>\n",
       "      <td>0.495027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>137</td>\n",
       "      <td>[mmXP_036171276.1, mbXP_005870752.1, mlXP_0061...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.482500</td>\n",
       "      <td>0.266168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>[mmXP_036184401.1, mlXP_023614665.1, mbXP_0144...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.661667</td>\n",
       "      <td>0.248280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>146</td>\n",
       "      <td>[mmXP_036193287.1, mlXP_006101042.1, mmXP_0361...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.477000</td>\n",
       "      <td>0.269386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>151</td>\n",
       "      <td>[mmXP_036198115.1, mmXP_036198115.1, mdXP_0595...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.332133</td>\n",
       "      <td>0.084259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>157</td>\n",
       "      <td>[mmXP_036207640.1, mmXP_036207640.1, mlXP_0236...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.485167</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>159</td>\n",
       "      <td>[mmXP_036207807.1, mlXP_006097347.1, mdXP_0595...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.496833</td>\n",
       "      <td>0.342946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>[paXP_024906107.1, pvXP_011377943.1, pvXP_0233...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324867</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>327</td>\n",
       "      <td>[pkXP_036313926.1, efXP_008139058.2, pnCAK6443...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.482167</td>\n",
       "      <td>0.297921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>385</td>\n",
       "      <td>[pvXP_023388578.1, pvXP_023388579.1, paXP_0249...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.486000</td>\n",
       "      <td>0.151397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cluster                                            members  cluster_size  \\\n",
       "51        51  [efXP_054585911.1, efXP_054585911.1, mmXP_0361...             7   \n",
       "61        61  [mbXP_005859726.1, mbXP_014389815.1, mdXP_0595...             6   \n",
       "64        64  [mbXP_005865977.1, efXP_008151575.2, mmXP_0361...             5   \n",
       "65        65  [mbXP_005869664.1, mbXP_005869664.1, mlXP_0236...             5   \n",
       "67        67  [mbXP_005871410.1, mlXP_006084398.1, mdXP_0595...             3   \n",
       "68        68  [mbXP_005875093.1, mlXP_023614664.1, mmXP_0361...             3   \n",
       "74        74  [mbXP_014386174.1, mdXP_059512329.1, mmXP_0361...             3   \n",
       "88        88  [mdXP_059525433.1, mlXP_006107817.3, mmXP_0361...             3   \n",
       "92        92  [mdXP_059536911.1, mdXP_059536910.1, mlXP_0143...             5   \n",
       "96        96  [mdXP_059549656.1, mlXP_006081093.1, mmXP_0361...             3   \n",
       "102      102  [mdXP_059564734.1, mlXP_006105618.2, mmXP_0361...             4   \n",
       "104      104  [mdXP_059567224.1, mmXP_036151819.1, mmXP_0361...             4   \n",
       "109      109  [mlXP_006084295.1, mbXP_014399301.1, mdXP_0595...             4   \n",
       "110      110  [mlXP_006085874.2, mmXP_036208711.1, mdXP_0595...             3   \n",
       "130      130  [mmXP_036157689.1, mmXP_036157689.1, mlXP_0143...             3   \n",
       "132      132  [mmXP_036158664.1, mdXP_059552641.1, mbXP_0143...             3   \n",
       "137      137  [mmXP_036171276.1, mbXP_005870752.1, mlXP_0061...             4   \n",
       "141      141  [mmXP_036184401.1, mlXP_023614665.1, mbXP_0144...             3   \n",
       "146      146  [mmXP_036193287.1, mlXP_006101042.1, mmXP_0361...             4   \n",
       "151      151  [mmXP_036198115.1, mmXP_036198115.1, mdXP_0595...             5   \n",
       "157      157  [mmXP_036207640.1, mmXP_036207640.1, mlXP_0236...             4   \n",
       "159      159  [mmXP_036207807.1, mlXP_006097347.1, mdXP_0595...             4   \n",
       "197      197  [paXP_024906107.1, pvXP_011377943.1, pvXP_0233...             6   \n",
       "327      327  [pkXP_036313926.1, efXP_008139058.2, pnCAK6443...             4   \n",
       "385      385  [pvXP_023388578.1, pvXP_023388579.1, paXP_0249...             4   \n",
       "\n",
       "     num_species  short_living_percentage  long_living_percentage  \\\n",
       "51             3                 0.000000                0.857143   \n",
       "61             4                 0.000000                1.000000   \n",
       "64             5                 0.000000                0.800000   \n",
       "65             5                 0.000000                0.800000   \n",
       "67             3                 0.000000                1.000000   \n",
       "68             3                 0.000000                1.000000   \n",
       "74             3                 0.000000                1.000000   \n",
       "88             3                 0.000000                1.000000   \n",
       "92             4                 0.000000                1.000000   \n",
       "96             3                 0.000000                1.000000   \n",
       "102            4                 0.000000                1.000000   \n",
       "104            3                 0.000000                1.000000   \n",
       "109            4                 0.000000                1.000000   \n",
       "110            3                 0.000000                1.000000   \n",
       "130            3                 0.000000                1.000000   \n",
       "132            3                 0.000000                1.000000   \n",
       "137            4                 0.000000                1.000000   \n",
       "141            3                 0.000000                1.000000   \n",
       "146            4                 0.000000                1.000000   \n",
       "151            4                 0.000000                1.000000   \n",
       "157            3                 0.000000                1.000000   \n",
       "159            4                 0.000000                1.000000   \n",
       "197            3                 0.833333                0.000000   \n",
       "327            3                 0.750000                0.000000   \n",
       "385            3                 0.750000                0.000000   \n",
       "\n",
       "     average_silhouette_pident  average_silhouette_evalue  \n",
       "51                    0.273429                   0.285714  \n",
       "61                    0.255600                   0.142307  \n",
       "64                    0.285700                   0.217733  \n",
       "65                    0.388700                   0.400000  \n",
       "67                    0.660333                   0.357502  \n",
       "68                    0.658000                   0.277214  \n",
       "74                    0.268641                   0.638889  \n",
       "88                    0.647000                   0.520361  \n",
       "92                    0.383500                   0.231022  \n",
       "96                    0.641000                   0.666667  \n",
       "102                   0.496833                   0.500000  \n",
       "104                   0.490167                   0.339759  \n",
       "109                   0.486500                   0.301040  \n",
       "110                   0.649333                   0.606463  \n",
       "130                   0.322000                   0.166989  \n",
       "132                   0.655333                   0.495027  \n",
       "137                   0.482500                   0.266168  \n",
       "141                   0.661667                   0.248280  \n",
       "146                   0.477000                   0.269386  \n",
       "151                   0.332133                   0.084259  \n",
       "157                   0.485167                   0.500000  \n",
       "159                   0.496833                   0.342946  \n",
       "197                   0.324867                   0.333333  \n",
       "327                   0.482167                   0.297921  \n",
       "385                   0.486000                   0.151397  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longevity_associated_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Silhouette Scores for Each Cluster\n",
      "     cluster  pident_silhouette  evalue_silhouette\n",
      "0          0           0.000000           0.000000\n",
      "1          1           0.157764           0.114562\n",
      "2          2           0.000000           0.000000\n",
      "3          3           0.000000           0.000000\n",
      "4          4           0.476833           0.500000\n",
      "..       ...                ...                ...\n",
      "410      410           0.033798           0.035573\n",
      "411      411           0.000000           0.000000\n",
      "412      412           0.024565           0.032569\n",
      "413      413           0.057053           0.023718\n",
      "414      414           0.008234           0.005363\n",
      "\n",
      "[415 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_samples\n",
    "\n",
    "# Ensure the distance matrices have zero on the diagonal for correct silhouette calculations\n",
    "np.fill_diagonal(pident_distance, 0)\n",
    "np.fill_diagonal(evalue_distance, 0)\n",
    "\n",
    "# Calculate silhouette scores for each sample based on pident and evalue distances\n",
    "pident_silhouette_samples = silhouette_samples(pident_distance, labels, metric=\"precomputed\")\n",
    "evalue_silhouette_samples = silhouette_samples(evalue_distance, labels, metric=\"precomputed\")\n",
    "\n",
    "# Create a DataFrame to store individual silhouette scores with cluster labels\n",
    "silhouette_df = pd.DataFrame({\n",
    "    \"protein\": [protein for protein, index in protein_index.items() if valid_indices[index]],\n",
    "    \"cluster\": labels,\n",
    "    \"pident_silhouette\": pident_silhouette_samples,\n",
    "    \"evalue_silhouette\": evalue_silhouette_samples\n",
    "})\n",
    "\n",
    "# Calculate average silhouette score for each cluster\n",
    "cluster_quality = silhouette_df.groupby(\"cluster\").agg({\n",
    "    \"pident_silhouette\": \"mean\",\n",
    "    \"evalue_silhouette\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "# Display results\n",
    "print(\"Average Silhouette Scores for Each Cluster\")\n",
    "print(cluster_quality)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOWER MIN SEQ ID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     representative                                             member\n",
      "0  ajXP_036987728.2  [ajXP_036987728.2, drXP_045041782.1, pdXP_0358...\n",
      "1  ajXP_036994466.2                                 [ajXP_036994466.2]\n",
      "2  ajXP_036995581.2  [ajXP_036995581.2, ajXP_036995581.2, ajXP_0369...\n",
      "3  ajXP_036997277.2  [ajXP_036997277.2, drXP_024413463.2, pdXP_0283...\n",
      "4  ajXP_037007824.2  [ajXP_037007824.2, phXP_045676151.1, pdXP_0358...\n"
     ]
    }
   ],
   "source": [
    "rbh_df = pd.read_csv(\"rbhecmaffilclusterslowid.tsv\", sep=\"\\t\", header=None, names=[\"representative\", \"member\"])\n",
    "\n",
    "aggregated_df = rbh_df.groupby(\"representative\")[\"member\"].apply(list).reset_index()\n",
    "\n",
    "print(aggregated_df.head())\n",
    "\n",
    "aggregated_df.to_csv(\"aggregated_ECMAFFIL_clusterslowid.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score based on pident: 0.06641958380570624\n",
      "Silhouette Score based on evalue: 0.05392867750899812\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Load the alignment data\n",
    "alignment_df = pd.read_csv(\"ecmaffillow_cluster_aligns.tsv\", sep=\"\\t\", \n",
    "                           names=[\"query\", \"target\", \"evalue\", \"pident\", \"alnlen\", \"qstart\", \"qend\", \"tstart\", \"tend\"])\n",
    "\n",
    "# Load clustering information with representative and members\n",
    "aggregated_df = pd.read_csv(\"aggregated_ECMAFFIL_clusterslowid.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Filter clusters with more than 1 unique protein and at least 2 different species\n",
    "filtered_clusters = []\n",
    "for _, row in aggregated_df.iterrows():\n",
    "    members = row[\"member\"].strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
    "    unique_prefixes = set(m[:2] for m in members)  # Get unique species prefixes\n",
    "\n",
    "    if len(members) > 1 and len(unique_prefixes) > 1:\n",
    "        filtered_clusters.append({\"representative\": row[\"representative\"], \"members\": members})\n",
    "\n",
    "# Create a combined list of all proteins across clusters\n",
    "all_proteins = {protein for cluster in filtered_clusters for protein in cluster[\"members\"]}\n",
    "protein_index = {protein: idx for idx, protein in enumerate(all_proteins)}\n",
    "num_proteins = len(all_proteins)\n",
    "\n",
    "# Initialize distance matrices for pident and evalue\n",
    "pident_matrix = np.zeros((num_proteins, num_proteins))\n",
    "evalue_matrix = np.zeros((num_proteins, num_proteins))\n",
    "\n",
    "# Populate matrices based on pairwise alignments\n",
    "for _, row in alignment_df.iterrows():\n",
    "    if row[\"query\"] in protein_index and row[\"target\"] in protein_index:\n",
    "        i, j = protein_index[row[\"query\"]], protein_index[row[\"target\"]]\n",
    "        pident_matrix[i, j] = row[\"pident\"] / 100  # Convert to fraction\n",
    "        pident_matrix[j, i] = row[\"pident\"] / 100\n",
    "        evalue_matrix[i, j] = -np.log(row[\"evalue\"] + 1e-300)\n",
    "        evalue_matrix[j, i] = -np.log(row[\"evalue\"] + 1e-300)\n",
    "\n",
    "# Convert similarity to distance for silhouette calculation\n",
    "pident_distance = 1 - pident_matrix\n",
    "evalue_distance = 1 - (evalue_matrix / np.max(evalue_matrix))\n",
    "\n",
    "# Create labels based on cluster membership\n",
    "labels = np.full(num_proteins, -1)  # Initialize with -1 for unassigned\n",
    "for cluster_id, cluster in enumerate(filtered_clusters):\n",
    "    for member in cluster[\"members\"]:\n",
    "        if member in protein_index:\n",
    "            labels[protein_index[member]] = cluster_id  # Assign cluster ID as label\n",
    "\n",
    "# Filter out unassigned proteins\n",
    "valid_indices = labels != -1\n",
    "# Convert similarity to distance for silhouette calculation\n",
    "pident_distance = 1 - pident_matrix\n",
    "evalue_distance = 1 - (evalue_matrix / np.max(evalue_matrix))  # Normalize evalue distances\n",
    "\n",
    "# Set diagonal to zero for both distance matrices\n",
    "np.fill_diagonal(pident_distance, 0)\n",
    "np.fill_diagonal(evalue_distance, 0)\n",
    "\n",
    "# Assign labels for silhouette calculation\n",
    "labels = labels[valid_indices]  # Ensure labels are only for valid indices\n",
    "\n",
    "# Calculate silhouette scores for both pident and evalue distances\n",
    "pident_silhouette_score = silhouette_score(pident_distance, labels, metric=\"precomputed\")\n",
    "evalue_silhouette_score = silhouette_score(evalue_distance, labels, metric=\"precomputed\")\n",
    "\n",
    "# Display results\n",
    "print(\"Silhouette Score based on pident:\", pident_silhouette_score)\n",
    "print(\"Silhouette Score based on evalue:\", evalue_silhouette_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Silhouette Score based on pident: 0.06641958380570624\n",
      "Overall Silhouette Score based on evalue: 0.05392867750899812\n",
      "\n",
      "Average Silhouette Scores for Each Cluster:\n",
      "     cluster  pident_silhouette  evalue_silhouette\n",
      "0          0           0.551980           0.625000\n",
      "1          1           0.403000           0.062791\n",
      "2          2           0.135667           0.078834\n",
      "3          3          -0.223427          -0.226867\n",
      "4          4          -0.407292          -0.082816\n",
      "..       ...                ...                ...\n",
      "261      261           0.214611           0.047046\n",
      "262      262           0.004279           0.002513\n",
      "263      263           0.052156           0.021752\n",
      "264      264           0.179178           0.054967\n",
      "265      265           0.399214           0.263694\n",
      "\n",
      "[266 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "# Load the alignment data\n",
    "alignment_df = pd.read_csv(\"ecmaffillow_cluster_aligns.tsv\", sep=\"\\t\", \n",
    "                           names=[\"query\", \"target\", \"evalue\", \"pident\", \"alnlen\", \"qstart\", \"qend\", \"tstart\", \"tend\"])\n",
    "\n",
    "# Load clustering information with representative and members\n",
    "aggregated_df = pd.read_csv(\"aggregated_ECMAFFIL_clusterslowid.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Filter clusters with more than 1 unique protein and at least 2 different species\n",
    "filtered_clusters = []\n",
    "for _, row in aggregated_df.iterrows():\n",
    "    members = row[\"member\"].strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
    "    unique_prefixes = set(m[:2] for m in members)  # Get unique species prefixes\n",
    "\n",
    "    if len(members) > 1 and len(unique_prefixes) > 1:\n",
    "        filtered_clusters.append({\"representative\": row[\"representative\"], \"members\": members})\n",
    "\n",
    "# Create a combined list of all proteins across clusters\n",
    "all_proteins = {protein for cluster in filtered_clusters for protein in cluster[\"members\"]}\n",
    "protein_index = {protein: idx for idx, protein in enumerate(all_proteins)}\n",
    "num_proteins = len(all_proteins)\n",
    "\n",
    "# Initialize distance matrices for pident and evalue\n",
    "pident_matrix = np.zeros((num_proteins, num_proteins))\n",
    "evalue_matrix = np.zeros((num_proteins, num_proteins))\n",
    "\n",
    "# Populate matrices based on pairwise alignments\n",
    "for _, row in alignment_df.iterrows():\n",
    "    if row[\"query\"] in protein_index and row[\"target\"] in protein_index:\n",
    "        i, j = protein_index[row[\"query\"]], protein_index[row[\"target\"]]\n",
    "        pident_matrix[i, j] = row[\"pident\"] / 100  # Convert to fraction\n",
    "        pident_matrix[j, i] = row[\"pident\"] / 100\n",
    "        evalue_matrix[i, j] = -np.log(row[\"evalue\"] + 1e-300)\n",
    "        evalue_matrix[j, i] = -np.log(row[\"evalue\"] + 1e-300)\n",
    "\n",
    "# Convert similarity to distance for silhouette calculation\n",
    "pident_distance = 1 - pident_matrix\n",
    "evalue_distance = 1 - (evalue_matrix / np.max(evalue_matrix))\n",
    "\n",
    "# Set diagonal to zero for both distance matrices\n",
    "np.fill_diagonal(pident_distance, 0)\n",
    "np.fill_diagonal(evalue_distance, 0)\n",
    "\n",
    "# Create labels based on cluster membership\n",
    "labels = np.full(num_proteins, -1)  # Initialize with -1 for unassigned\n",
    "for cluster_id, cluster in enumerate(filtered_clusters):\n",
    "    for member in cluster[\"members\"]:\n",
    "        if member in protein_index:\n",
    "            labels[protein_index[member]] = cluster_id  # Assign cluster ID as label\n",
    "\n",
    "# Filter out unassigned proteins\n",
    "valid_indices = labels != -1\n",
    "pident_distance = pident_distance[valid_indices][:, valid_indices]\n",
    "evalue_distance = evalue_distance[valid_indices][:, valid_indices]\n",
    "labels = labels[valid_indices]\n",
    "\n",
    "# Calculate silhouette scores for each sample based on pident and evalue distances\n",
    "pident_silhouette_samples = silhouette_samples(pident_distance, labels, metric=\"precomputed\")\n",
    "evalue_silhouette_samples = silhouette_samples(evalue_distance, labels, metric=\"precomputed\")\n",
    "\n",
    "# Create a DataFrame to store individual silhouette scores with cluster labels\n",
    "silhouette_df = pd.DataFrame({\n",
    "    \"protein\": [protein for protein, index in protein_index.items() if valid_indices[index]],\n",
    "    \"cluster\": labels,\n",
    "    \"pident_silhouette\": pident_silhouette_samples,\n",
    "    \"evalue_silhouette\": evalue_silhouette_samples\n",
    "})\n",
    "\n",
    "# Calculate average silhouette score for each cluster\n",
    "cluster_quality = silhouette_df.groupby(\"cluster\").agg({\n",
    "    \"pident_silhouette\": \"mean\",\n",
    "    \"evalue_silhouette\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "# Display results\n",
    "print(\"Overall Silhouette Score based on pident:\", silhouette_score(pident_distance, labels, metric=\"precomputed\"))\n",
    "print(\"Overall Silhouette Score based on evalue:\", silhouette_score(evalue_distance, labels, metric=\"precomputed\"))\n",
    "print(\"\\nAverage Silhouette Scores for Each Cluster:\")\n",
    "print(cluster_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Silhouette Scores for Each Cluster:\n",
      "     cluster  pident_silhouette  evalue_silhouette\n",
      "0          0           0.551980           0.625000\n",
      "1          1           0.403000           0.062791\n",
      "2          2           0.135667           0.078834\n",
      "3          3          -0.223427          -0.226867\n",
      "4          4          -0.407292          -0.082816\n",
      "..       ...                ...                ...\n",
      "261      261           0.214611           0.047046\n",
      "262      262           0.004279           0.002513\n",
      "263      263           0.052156           0.021752\n",
      "264      264           0.179178           0.054967\n",
      "265      265           0.399214           0.263694\n",
      "\n",
      "[266 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "# Ensure diagonal elements are zero for silhouette calculation\n",
    "np.fill_diagonal(pident_distance, 0)\n",
    "np.fill_diagonal(evalue_distance, 0)\n",
    "\n",
    "# Filter out unassigned proteins and keep original protein IDs\n",
    "valid_protein_ids = [protein for protein, index in protein_index.items() if valid_indices[index]]\n",
    "labels = labels[valid_indices]\n",
    "pident_distance = pident_distance[valid_indices][:, valid_indices]\n",
    "evalue_distance = evalue_distance[valid_indices][:, valid_indices]\n",
    "\n",
    "# Calculate silhouette scores for each sample based on pident and evalue distances\n",
    "pident_silhouette_samples = silhouette_samples(pident_distance, labels, metric=\"precomputed\")\n",
    "evalue_silhouette_samples = silhouette_samples(evalue_distance, labels, metric=\"precomputed\")\n",
    "\n",
    "# Create a DataFrame to store protein IDs, cluster labels, and silhouette scores\n",
    "silhouette_df = pd.DataFrame({\n",
    "    \"protein\": valid_protein_ids,  # Proper protein IDs instead of indexes\n",
    "    \"cluster\": labels,\n",
    "    \"pident_silhouette\": pident_silhouette_samples,\n",
    "    \"evalue_silhouette\": evalue_silhouette_samples\n",
    "})\n",
    "\n",
    "# Calculate the average silhouette score for each cluster\n",
    "cluster_quality = silhouette_df.groupby(\"cluster\").agg({\n",
    "    \"pident_silhouette\": \"mean\",\n",
    "    \"evalue_silhouette\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "# Display results\n",
    "print(\"Average Silhouette Scores for Each Cluster:\")\n",
    "print(cluster_quality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Silhouette Scores and Members for Each Cluster:\n",
      "     cluster  pident_silhouette  evalue_silhouette  \\\n",
      "0          0           0.551980           0.625000   \n",
      "1          1           0.403000           0.062791   \n",
      "2          2           0.135667           0.078834   \n",
      "3          3          -0.223427          -0.226867   \n",
      "4          4          -0.407292          -0.082816   \n",
      "..       ...                ...                ...   \n",
      "261      261           0.214611           0.047046   \n",
      "262      262           0.004279           0.002513   \n",
      "263      263           0.052156           0.021752   \n",
      "264      264           0.179178           0.054967   \n",
      "265      265           0.399214           0.263694   \n",
      "\n",
      "                                       cluster_members  \n",
      "0    [ajXP_036987728.2, drXP_045041782.1, pdXP_0358...  \n",
      "1    [ajXP_036997277.2, drXP_024413463.2, pdXP_0283...  \n",
      "2    [ajXP_037007824.2, phXP_045676151.1, pdXP_0358...  \n",
      "3    [ajXP_037021117.2, phXP_045687379.1, phXP_0456...  \n",
      "4    [ajXP_037022011.2, pdXP_028372235.1, raXP_0160...  \n",
      "..                                                 ...  \n",
      "261  [sbXP_066124233.1, moXP_036129550.1, moXP_0361...  \n",
      "262  [sbXP_066132351.1, rfXP_032964635.1, drXP_0537...  \n",
      "263  [sbXP_066133315.1, moXP_036138040.1, mdXP_0595...  \n",
      "264  [sbXP_066133767.1, pvXP_023388579.1, pvXP_0233...  \n",
      "265  [sbXP_066134608.1, moXP_036096531.1, sbXP_0661...  \n",
      "\n",
      "[266 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary that maps each cluster ID to the list of members (protein IDs) in that cluster\n",
    "cluster_members_dict = {\n",
    "    cluster_id: cluster[\"members\"]\n",
    "    for cluster_id, cluster in enumerate(filtered_clusters)\n",
    "}\n",
    "\n",
    "# Map each row in silhouette_df to its respective cluster members\n",
    "silhouette_df[\"cluster_members\"] = silhouette_df[\"cluster\"].map(cluster_members_dict)\n",
    "\n",
    "# Group by cluster to get average silhouette scores and list of cluster members\n",
    "cluster_quality = silhouette_df.groupby(\"cluster\").agg({\n",
    "    \"pident_silhouette\": \"mean\",\n",
    "    \"evalue_silhouette\": \"mean\",\n",
    "    \"cluster_members\": \"first\"  # List of members in each cluster\n",
    "}).reset_index()\n",
    "\n",
    "# Display results\n",
    "print(\"Average Silhouette Scores and Members for Each Cluster:\")\n",
    "print(cluster_quality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longevity-Associated Clusters with at least 3 Proteins, 3 Species, and Silhouette Score > 0.25 for either measure:\n",
      "     cluster                                            members  cluster_size  \\\n",
      "65        65  [mbXP_014385769.1, mlXP_006097188.1, mdXP_0595...             3   \n",
      "67        67  [mbXP_014394036.1, mdXP_059551677.1, mmXP_0361...             3   \n",
      "79        79  [mdXP_059536866.1, mbXP_014399304.1, mmXP_0361...             4   \n",
      "89        89  [mdXP_059568003.1, mmXP_036184401.1, mmXP_0361...             8   \n",
      "261      261  [sbXP_066124233.1, moXP_036129550.1, moXP_0361...             6   \n",
      "\n",
      "     num_species  short_living_percentage  long_living_percentage  \\\n",
      "65             3                 0.000000                1.000000   \n",
      "67             3                 0.000000                1.000000   \n",
      "79             4                 0.000000                1.000000   \n",
      "89             4                 0.000000                1.000000   \n",
      "261            3                 0.833333                0.166667   \n",
      "\n",
      "     average_silhouette_pident  average_silhouette_evalue  \n",
      "65                    0.359162                   0.206731  \n",
      "67                    0.614732                   0.384562  \n",
      "79                    0.429969                   0.084651  \n",
      "89                    0.153130                   0.055450  \n",
      "261                   0.214611                   0.047046  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Леонид\\AppData\\Local\\Temp\\ipykernel_46212\\2487127128.py:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cluster_longevity = silhouette_df.groupby(\"cluster\").apply(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define longevity-associated prefixes\n",
    "short_living_prefixes = {'sb', 'pn', 'pk', 'mo', 'pd', 'pv', 'pa'}\n",
    "average_living_prefixes = {'en', 'ef', 'ph', 'aj', 'ra', 'pg'}\n",
    "long_living_prefixes = {'mb', 'md', 'ml', 'mm', 'dr', 'rf'}\n",
    "\n",
    "# Function to determine the longevity category based on prefix\n",
    "def get_longevity_category(prefix):\n",
    "    if prefix in short_living_prefixes:\n",
    "        return \"short\"\n",
    "    elif prefix in average_living_prefixes:\n",
    "        return \"average\"\n",
    "    elif prefix in long_living_prefixes:\n",
    "        return \"long\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Add a new column to silhouette_df with the longevity category and species prefix\n",
    "silhouette_df[\"longevity\"] = silhouette_df[\"protein\"].apply(lambda x: get_longevity_category(x[:2]))\n",
    "silhouette_df[\"species_prefix\"] = silhouette_df[\"protein\"].apply(lambda x: x[:2])\n",
    "\n",
    "# Group by cluster and analyze the longevity distribution, species diversity, and silhouette score\n",
    "cluster_longevity = silhouette_df.groupby(\"cluster\").apply(\n",
    "    lambda df: pd.Series({\n",
    "        \"members\": df[\"cluster_members\"].iloc[0],  # List of cluster members\n",
    "        \"cluster_size\": len(df),  # Total number of proteins in the cluster\n",
    "        \"num_species\": df[\"species_prefix\"].nunique(),  # Number of unique species (prefixes)\n",
    "        \"short_living_percentage\": (df[\"longevity\"] == \"short\").mean(),\n",
    "        \"long_living_percentage\": (df[\"longevity\"] == \"long\").mean(),\n",
    "        \"average_silhouette_pident\": df[\"pident_silhouette\"].mean(),\n",
    "        \"average_silhouette_evalue\": df[\"evalue_silhouette\"].mean()\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "# Filter clusters to meet the criteria:\n",
    "# - At least 3 proteins in the cluster\n",
    "# - At least 3 different species (prefixes)\n",
    "# - Either at least 75% short-living or long-living members\n",
    "# - At least one of the silhouette scores is higher than 0.25\n",
    "longevity_associated_clusters = cluster_longevity[\n",
    "    ((cluster_longevity[\"short_living_percentage\"] >= 0.75) | \n",
    "     (cluster_longevity[\"long_living_percentage\"] >= 0.75)) & \n",
    "    (cluster_longevity[\"cluster_size\"] >= 3) & \n",
    "    (cluster_longevity[\"num_species\"] >= 3) &\n",
    "    ((cluster_longevity[\"average_silhouette_pident\"] > 0.1) |\n",
    "     (cluster_longevity[\"average_silhouette_evalue\"] > 0.1))\n",
    "]\n",
    "\n",
    "# Display the longevity-associated clusters with silhouette scores\n",
    "print(\"Longevity-Associated Clusters with at least 3 Proteins, 3 Species, and Silhouette Score > 0.25 for either measure:\")\n",
    "print(longevity_associated_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "longevity_associated_clusters.to_csv(\"longevityecmaffilclustLOW.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regenerating islet-derived protein 4 is similar within short-living Saccopteryx bileniata and Molossus molossus (also, sadly, long-living Rhinolophus ferrumequinum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter silhouette_df to include only longevity-associated clusters\n",
    "longevity_clusters = longevity_associated_clusters[\"cluster\"].tolist()\n",
    "filtered_silhouette_df = silhouette_df[silhouette_df[\"cluster\"].isin(longevity_clusters)]\n",
    "\n",
    "# Create a new NetworkX graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes for each protein, color by longevity category\n",
    "for _, row in filtered_silhouette_df.iterrows():\n",
    "    protein = row[\"protein\"]\n",
    "    cluster_id = row[\"cluster\"]\n",
    "    longevity = row[\"longevity\"]\n",
    "    color = 'green' if longevity == 'short' else 'yellow' if longevity == 'average' else 'red'\n",
    "    G.add_node(protein, cluster=cluster_id, color=color)\n",
    "\n",
    "# Add intra-cluster edges based on pident within each cluster\n",
    "for cluster_id in longevity_clusters:\n",
    "    cluster_proteins = filtered_silhouette_df[filtered_silhouette_df[\"cluster\"] == cluster_id]\n",
    "    for i, row1 in cluster_proteins.iterrows():\n",
    "        for j, row2 in cluster_proteins.iterrows():\n",
    "            if i < j:  # Avoid duplicate edges and self-loops\n",
    "                query, target = row1[\"protein\"], row2[\"protein\"]\n",
    "                # Get the pident score between query and target (or a representative score)\n",
    "                alignment_row = alignment_df[((alignment_df[\"query\"] == query) & (alignment_df[\"target\"] == target)) |\n",
    "                                             ((alignment_df[\"query\"] == target) & (alignment_df[\"target\"] == query))]\n",
    "                if not alignment_row.empty:\n",
    "                    pident = alignment_row[\"pident\"].iloc[0]\n",
    "                    G.add_edge(query, target, weight=pident / 10)  # Scale down pident to avoid excessive line thickness\n",
    "\n",
    "# Add inter-cluster edges based on average silhouette score for each cluster\n",
    "for i, cluster1 in enumerate(longevity_clusters):\n",
    "    for j, cluster2 in enumerate(longevity_clusters):\n",
    "        if i < j:  # Avoid duplicate edges\n",
    "            cluster1_members = filtered_silhouette_df[filtered_silhouette_df[\"cluster\"] == cluster1][\"protein\"].tolist()\n",
    "            cluster2_members = filtered_silhouette_df[filtered_silhouette_df[\"cluster\"] == cluster2][\"protein\"].tolist()\n",
    "            silhouette_score = longevity_associated_clusters[\n",
    "                longevity_associated_clusters[\"cluster\"] == cluster1\n",
    "            ][\"average_silhouette_pident\"].values[0]\n",
    "\n",
    "            # Connect all proteins between clusters with silhouette score as weight\n",
    "            for protein1 in cluster1_members:\n",
    "                for protein2 in cluster2_members:\n",
    "                    G.add_edge(protein1, protein2, weight=silhouette_score, style=\"bold\")\n",
    "\n",
    "# Draw the network\n",
    "plt.figure(figsize=(12, 12))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "# Draw nodes with color by longevity\n",
    "node_colors = [G.nodes[node]['color'] for node in G.nodes()]\n",
    "nx.draw_networkx_nodes(G, pos, node_size=100, node_color=node_colors)\n",
    "\n",
    "# Draw edges with thickness based on weights\n",
    "for u, v, data in G.edges(data=True):\n",
    "    width = data['weight'] if 'style' not in data else data['weight'] * 3  # Make inter-cluster edges thicker\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=[(u, v)], width=width, edge_color=\"black\" if 'style' in data else \"gray\")\n",
    "\n",
    "# Add node labels\n",
    "nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "\n",
    "plt.title(\"Longevity-Associated Clusters Network\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Define longevity-associated prefixes\n",
    "short_living_prefixes = {'sb', 'pn', 'pk', 'mo', 'pd', 'pv', 'pa'}\n",
    "average_living_prefixes = {'en', 'ef', 'ph', 'aj', 'ra', 'pg'}\n",
    "long_living_prefixes = {'mb', 'md', 'ml', 'mm', 'dr', 'rf'}\n",
    "\n",
    "# Function to determine the longevity category based on prefix\n",
    "def get_longevity_category(prefix):\n",
    "    if prefix in short_living_prefixes:\n",
    "        return \"green\"\n",
    "    elif prefix in average_living_prefixes:\n",
    "        return \"yellow\"\n",
    "    elif prefix in long_living_prefixes:\n",
    "        return \"red\"\n",
    "    else:\n",
    "        return \"gray\"\n",
    "\n",
    "# Load your data\n",
    "alignment_df = pd.read_csv(\"ecmaffillow_cluster_aligns.tsv\", sep=\"\\t\", \n",
    "                           names=[\"query\", \"target\", \"evalue\", \"pident\", \"alnlen\", \"qstart\", \"qend\", \"tstart\", \"tend\"])\n",
    "\n",
    "aggregated_df = pd.read_csv(\"aggregated_ECMAFFIL_clusterslowid.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Calculate silhouette scores, filter clusters, and prepare longevity_associated_clusters as in previous code\n",
    "# Assume longevity_associated_clusters is prepared and has the columns \"cluster\", \"members\", and \"average_silhouette_pident\"\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(16, 16))  # Increased figure size\n",
    "expanded_radius = 10  # Increase this value for more space between clusters\n",
    "cluster_positions = np.linspace(0, 2 * np.pi, len(longevity_associated_clusters), endpoint=False)\n",
    "\n",
    "for idx, (index, cluster) in enumerate(longevity_associated_clusters.iterrows()):\n",
    "    # Convert members column to list if it's in string format\n",
    "    if isinstance(cluster[\"members\"], str):\n",
    "        members = ast.literal_eval(cluster[\"members\"])  # Safely convert string to list\n",
    "    else:\n",
    "        members = cluster[\"members\"]\n",
    "    \n",
    "    silhouette_score = cluster[\"average_silhouette_pident\"]\n",
    "    \n",
    "    # Define cluster circle properties\n",
    "    cluster_position = (expanded_radius * np.cos(cluster_positions[idx]), expanded_radius * np.sin(cluster_positions[idx]))\n",
    "    circle_radius = 0.6 + 0.1 * len(members)  # Adjusted radius\n",
    "    circle = plt.Circle(cluster_position, circle_radius, color='black', fill=False, \n",
    "                        linewidth=silhouette_score * 4)  # Scale outline by silhouette score\n",
    "    plt.gca().add_artist(circle)\n",
    "    \n",
    "    # Set the first member as the representative\n",
    "    representative = members[0] if members else None\n",
    "\n",
    "    # Position proteins within the cluster circle\n",
    "    angles = np.linspace(0, 2 * np.pi, len(members), endpoint=False)\n",
    "    for i, protein in enumerate(members):\n",
    "        protein_color = get_longevity_category(protein[:2])  # Color by longevity\n",
    "        x = cluster_position[0] + circle_radius * 0.7 * np.cos(angles[i])\n",
    "        y = cluster_position[1] + circle_radius * 0.7 * np.sin(angles[i])\n",
    "\n",
    "        # Make the representative protein larger\n",
    "        marker_size = 12 if protein == representative else 8\n",
    "        plt.plot(x, y, 'o', color=protein_color, markersize=marker_size)\n",
    "        \n",
    "        # Add labels to each protein\n",
    "        plt.text(x, y, protein, fontsize=6, ha='center', va='center')\n",
    "\n",
    "        # Draw connections between all proteins in the cluster\n",
    "        for j in range(i + 1, len(members)):\n",
    "            x2 = cluster_position[0] + circle_radius * 0.7 * np.cos(angles[j])\n",
    "            y2 = cluster_position[1] + circle_radius * 0.7 * np.sin(angles[j])\n",
    "            plt.plot([x, x2], [y, y2], color=\"gray\", linewidth=1)  # Uniform line width for all connections\n",
    "\n",
    "# Display plot\n",
    "plt.axis('off')\n",
    "plt.title(\"Longevity-Associated Clusters Network (Only Within-Cluster Connections)\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Define longevity-associated prefixes\n",
    "short_living_prefixes = {'sb', 'pn', 'pk', 'mo', 'pd', 'pv', 'pa'}\n",
    "average_living_prefixes = {'en', 'ef', 'ph', 'aj', 'ra', 'pg'}\n",
    "long_living_prefixes = {'mb', 'md', 'ml', 'mm', 'dr', 'rf'}\n",
    "\n",
    "# Function to determine the longevity category based on prefix\n",
    "def get_longevity_category(prefix):\n",
    "    if prefix in short_living_prefixes:\n",
    "        return \"green\"\n",
    "    elif prefix in average_living_prefixes:\n",
    "        return \"yellow\"\n",
    "    elif prefix in long_living_prefixes:\n",
    "        return \"red\"\n",
    "    else:\n",
    "        return \"gray\"\n",
    "\n",
    "# Load your data\n",
    "alignment_df = pd.read_csv(\"ecmaffillow_cluster_aligns.tsv\", sep=\"\\t\", \n",
    "                           names=[\"query\", \"target\", \"evalue\", \"pident\", \"alnlen\", \"qstart\", \"qend\", \"tstart\", \"tend\"])\n",
    "\n",
    "aggregated_df = pd.read_csv(\"aggregated_ECMAFFIL_clusters.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Calculate silhouette scores, filter clusters, and prepare longevity_associated_clusters as in previous code\n",
    "# Assume longevity_associated_clusters is prepared and has the columns \"cluster\", \"members\", and \"average_silhouette_pident\"\n",
    "\n",
    "# Set up the plot with a grid layout\n",
    "plt.figure(figsize=(20, 20))  # Larger figure size for better spacing\n",
    "grid_size = int(np.ceil(np.sqrt(len(longevity_associated_clusters))))  # Determine grid size (e.g., 5x5 for 25 clusters)\n",
    "spacing = 7  # Adjust this value for more space between clusters\n",
    "\n",
    "for idx, (index, cluster) in enumerate(longevity_associated_clusters.iterrows()):\n",
    "    # Convert members column to list if it's in string format\n",
    "    if isinstance(cluster[\"members\"], str):\n",
    "        members = ast.literal_eval(cluster[\"members\"])  # Safely convert string to list\n",
    "    else:\n",
    "        members = cluster[\"members\"]\n",
    "    \n",
    "    silhouette_score = cluster[\"average_silhouette_pident\"]\n",
    "    \n",
    "    # Define grid position for each cluster\n",
    "    row, col = divmod(idx, grid_size)\n",
    "    cluster_position = (col * spacing, -row * spacing)  # Adjust y-axis to go downward for each row\n",
    "\n",
    "    circle_radius = 0.6 + 0.1 * len(members)  # Adjusted radius based on cluster size\n",
    "    circle = plt.Circle(cluster_position, circle_radius, color='black', fill=False, \n",
    "                        linewidth=silhouette_score * 4)  # Scale outline by silhouette score\n",
    "    plt.gca().add_artist(circle)\n",
    "    \n",
    "    # Set the first member as the representative\n",
    "    representative = members[0] if members else None\n",
    "\n",
    "    # Position proteins within the cluster circle\n",
    "    angles = np.linspace(0, 2 * np.pi, len(members), endpoint=False)\n",
    "    for i, protein in enumerate(members):\n",
    "        protein_color = get_longevity_category(protein[:2])  # Color by longevity\n",
    "        x = cluster_position[0] + circle_radius * 0.7 * np.cos(angles[i])\n",
    "        y = cluster_position[1] + circle_radius * 0.7 * np.sin(angles[i])\n",
    "\n",
    "        # Make the representative protein larger\n",
    "        marker_size = 12 if protein == representative else 8\n",
    "        plt.plot(x, y, 'o', color=protein_color, markersize=marker_size)\n",
    "        \n",
    "        # Add labels to each protein\n",
    "        plt.text(x, y, protein, fontsize=6, ha='center', va='center')\n",
    "\n",
    "        # Draw connections between all proteins in the cluster\n",
    "        for j in range(i + 1, len(members)):\n",
    "            x2 = cluster_position[0] + circle_radius * 0.7 * np.cos(angles[j])\n",
    "            y2 = cluster_position[1] + circle_radius * 0.7 * np.sin(angles[j])\n",
    "            plt.plot([x, x2], [y, y2], color=\"gray\", linewidth=1)  # Uniform line width for all connections\n",
    "\n",
    "# Display plot\n",
    "plt.axis('off')\n",
    "plt.title(\"Longevity-Associated Clusters Network (Grid Layout, Only Within-Cluster Connections)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Леонид\\AppData\\Local\\Temp\\ipykernel_24188\\2200656267.py:41: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = cm.get_cmap('viridis')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Define longevity-associated prefixes\n",
    "short_living_prefixes = {'sb', 'pn', 'pk', 'mo', 'pd', 'pv', 'pa'}\n",
    "average_living_prefixes = {'en', 'ef', 'ph', 'aj', 'ra', 'pg'}\n",
    "long_living_prefixes = {'mb', 'md', 'ml', 'mm', 'dr', 'rf'}\n",
    "\n",
    "# Function to determine the longevity category based on prefix\n",
    "def get_longevity_category(prefix):\n",
    "    if prefix in short_living_prefixes:\n",
    "        return \"green\"\n",
    "    elif prefix in average_living_prefixes:\n",
    "        return \"yellow\"\n",
    "    elif prefix in long_living_prefixes:\n",
    "        return \"red\"\n",
    "    else:\n",
    "        return \"gray\"\n",
    "\n",
    "# Load your data\n",
    "alignment_df = pd.read_csv(\"ecmaffillow_cluster_aligns.tsv\", sep=\"\\t\", \n",
    "                           names=[\"query\", \"target\", \"evalue\", \"pident\", \"alnlen\", \"qstart\", \"qend\", \"tstart\", \"tend\"])\n",
    "\n",
    "aggregated_df = pd.read_csv(\"aggregated_ECMAFFIL_clusters.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Calculate silhouette scores, filter clusters, and prepare longevity_associated_clusters as in previous code\n",
    "# Assume longevity_associated_clusters is prepared and has the columns \"cluster\", \"members\", and \"average_silhouette_pident\"\n",
    "\n",
    "# Set up the plot with a grid layout\n",
    "fig, ax = plt.subplots(figsize=(20, 20))  # Larger figure size for better spacing\n",
    "grid_size = int(np.ceil(np.sqrt(len(longevity_associated_clusters))))  # Determine grid size (e.g., 5x5 for 25 clusters)\n",
    "spacing = 7  # Adjust this value for more space between clusters\n",
    "\n",
    "# Set up color mapping for silhouette scores\n",
    "norm = mcolors.Normalize(vmin=longevity_associated_clusters[\"average_silhouette_pident\"].min(),\n",
    "                         vmax=longevity_associated_clusters[\"average_silhouette_pident\"].max())\n",
    "cmap = cm.get_cmap('viridis')\n",
    "\n",
    "# Dummy scatter for color bar\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])  # This is needed to create a color bar\n",
    "\n",
    "for idx, (index, cluster) in enumerate(longevity_associated_clusters.iterrows()):\n",
    "    # Convert members column to list if it's in string format\n",
    "    if isinstance(cluster[\"members\"], str):\n",
    "        members = ast.literal_eval(cluster[\"members\"])  # Safely convert string to list\n",
    "    else:\n",
    "        members = cluster[\"members\"]\n",
    "    \n",
    "    silhouette_score = cluster[\"average_silhouette_pident\"]\n",
    "    \n",
    "    # Define grid position for each cluster\n",
    "    row, col = divmod(idx, grid_size)\n",
    "    cluster_position = (col * spacing, -row * spacing)  # Adjust y-axis to go downward for each row\n",
    "\n",
    "    circle_radius = 0.6 + 0.1 * len(members)  # Adjusted radius based on cluster size\n",
    "    outline_color = cmap(norm(silhouette_score))  # Map silhouette score to color\n",
    "    circle = plt.Circle(cluster_position, circle_radius, color=outline_color, fill=False, \n",
    "                        linewidth=2 + silhouette_score * 2)  # Outline width based on silhouette score\n",
    "    ax.add_artist(circle)\n",
    "    \n",
    "    # Set the first member as the representative\n",
    "    representative = members[0] if members else None\n",
    "\n",
    "    # Position proteins within the cluster circle\n",
    "    angles = np.linspace(0, 2 * np.pi, len(members), endpoint=False)\n",
    "    for i, protein in enumerate(members):\n",
    "        protein_color = get_longevity_category(protein[:2])  # Color by longevity\n",
    "        x = cluster_position[0] + circle_radius * 0.7 * np.cos(angles[i])\n",
    "        y = cluster_position[1] + circle_radius * 0.7 * np.sin(angles[i])\n",
    "\n",
    "        # Make the representative protein larger\n",
    "        marker_size = 8 #12 if protein == representative else 8\n",
    "        ax.plot(x, y, 'o', color=protein_color, markersize=marker_size)\n",
    "        \n",
    "        # Add labels to each protein\n",
    "        ax.text(x, y, protein, fontsize=6, ha='center', va='center')\n",
    "\n",
    "        # Draw connections between all proteins in the cluster\n",
    "        for j in range(i + 1, len(members)):\n",
    "            x2 = cluster_position[0] + circle_radius * 0.7 * np.cos(angles[j])\n",
    "            y2 = cluster_position[1] + circle_radius * 0.7 * np.sin(angles[j])\n",
    "            ax.plot([x, x2], [y, y2], color=\"gray\", linewidth=1)  # Uniform line width for all connections\n",
    "\n",
    "# Add color bar outside the plot\n",
    "cbar = fig.colorbar(sm, ax=ax, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "cbar.set_label(\"Silhouette Score (pident-based)\", rotation=90)\n",
    "\n",
    "# Disable axis labels and ticks\n",
    "ax.axis('off')\n",
    "\n",
    "plt.title(\"Longevity-Associated Clusters Network (Grid Layout, Only Within-Cluster Connections)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Леонид\\AppData\\Local\\Temp\\ipykernel_24188\\1361955962.py:40: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = cm.get_cmap('viridis')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Define longevity-associated prefixes\n",
    "short_living_prefixes = {'sb', 'pn', 'pk', 'mo', 'pd', 'pv', 'pa'}\n",
    "average_living_prefixes = {'en', 'ef', 'ph', 'aj', 'ra', 'pg'}\n",
    "long_living_prefixes = {'mb', 'md', 'ml', 'mm', 'dr', 'rf'}\n",
    "\n",
    "# Function to determine the longevity category based on prefix\n",
    "def get_longevity_category(prefix):\n",
    "    if prefix in short_living_prefixes:\n",
    "        return \"green\"\n",
    "    elif prefix in average_living_prefixes:\n",
    "        return \"yellow\"\n",
    "    elif prefix in long_living_prefixes:\n",
    "        return \"red\"\n",
    "    else:\n",
    "        return \"gray\"\n",
    "\n",
    "# Load your data\n",
    "alignment_df = pd.read_csv(\"ecmaffillow_cluster_aligns.tsv\", sep=\"\\t\", \n",
    "                           names=[\"query\", \"target\", \"evalue\", \"pident\", \"alnlen\", \"qstart\", \"qend\", \"tstart\", \"tend\"])\n",
    "\n",
    "aggregated_df = pd.read_csv(\"aggregated_ECMAFFIL_clusters.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Assume longevity_associated_clusters is prepared and has the columns \"cluster\", \"members\", and \"average_silhouette_pident\"\n",
    "\n",
    "# Set up the plot with a grid layout\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "grid_size = int(np.ceil(np.sqrt(len(longevity_associated_clusters))))\n",
    "spacing = 7\n",
    "\n",
    "# Set up color mapping for silhouette scores\n",
    "norm = mcolors.Normalize(vmin=longevity_associated_clusters[\"average_silhouette_pident\"].min(),\n",
    "                         vmax=longevity_associated_clusters[\"average_silhouette_pident\"].max())\n",
    "cmap = cm.get_cmap('viridis')\n",
    "\n",
    "# Dummy scatter for color bar\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "for idx, (index, cluster) in enumerate(longevity_associated_clusters.iterrows()):\n",
    "    # Convert members column to list if it's in string format\n",
    "    if isinstance(cluster[\"members\"], str):\n",
    "        members = list(set(ast.literal_eval(cluster[\"members\"])))  # Remove duplicates\n",
    "    else:\n",
    "        members = list(set(cluster[\"members\"]))\n",
    "\n",
    "    silhouette_score = cluster[\"average_silhouette_pident\"]\n",
    "    \n",
    "    # Define grid position for each cluster\n",
    "    row, col = divmod(idx, grid_size)\n",
    "    cluster_position = (col * spacing, -row * spacing)\n",
    "\n",
    "    circle_radius = 0.6 + 0.1 * len(members)\n",
    "    outline_color = cmap(norm(silhouette_score))\n",
    "    circle = plt.Circle(cluster_position, circle_radius, color=outline_color, fill=False, linewidth=2 + silhouette_score * 2)\n",
    "    ax.add_artist(circle)\n",
    "    \n",
    "    # Position proteins within the cluster circle\n",
    "    angles = np.linspace(0, 2 * np.pi, len(members), endpoint=False)\n",
    "    protein_positions = {}\n",
    "\n",
    "    for i, protein in enumerate(members):\n",
    "        protein_color = get_longevity_category(protein[:2])\n",
    "        x = cluster_position[0] + circle_radius * 0.7 * np.cos(angles[i])\n",
    "        y = cluster_position[1] + circle_radius * 0.7 * np.sin(angles[i])\n",
    "        protein_positions[protein] = (x, y)\n",
    "        ax.plot(x, y, 'o', color=protein_color, markersize=8)\n",
    "        ax.text(x, y, protein, fontsize=6, ha='center', va='center')\n",
    "\n",
    "    # Draw connections between all proteins in the cluster with a uniform line width\n",
    "    for i, protein1 in enumerate(members):\n",
    "        for j in range(i + 1, len(members)):\n",
    "            protein2 = members[j]\n",
    "            x1, y1 = protein_positions[protein1]\n",
    "            x2, y2 = protein_positions[protein2]\n",
    "            ax.plot([x1, x2], [y1, y2], color=\"gray\", linewidth=1)  # Uniform line width for all connections\n",
    "\n",
    "# Add color bar outside the plot\n",
    "cbar = fig.colorbar(sm, ax=ax, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "cbar.set_label(\"Silhouette Score (pident-based)\", rotation=90)\n",
    "\n",
    "# Disable axis labels and ticks\n",
    "ax.axis('off')\n",
    "\n",
    "plt.title(\"Longevity-Associated Clusters Network (Grid Layout, Only Within-Cluster Connections)\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Define longevity-associated prefixes and color mapping\n",
    "short_living_prefixes = {'sb', 'pn', 'pk', 'mo', 'pd', 'pv', 'pa'}\n",
    "average_living_prefixes = {'en', 'ef', 'ph', 'aj', 'ra', 'pg'}\n",
    "long_living_prefixes = {'mb', 'md', 'ml', 'mm', 'dr', 'rf'}\n",
    "\n",
    "# Function to determine color based on longevity category\n",
    "def get_longevity_category(prefix):\n",
    "    if prefix in short_living_prefixes:\n",
    "        return \"green\"\n",
    "    elif prefix in average_living_prefixes:\n",
    "        return \"yellow\"\n",
    "    elif prefix in long_living_prefixes:\n",
    "        return \"red\"\n",
    "    else:\n",
    "        return \"gray\"\n",
    "\n",
    "# Assuming `longevity_associated_clusters` and `pident_distance` are prepared and ready for use\n",
    "\n",
    "# Calculate inter-cluster average identity scores\n",
    "cluster_similarities = {}\n",
    "for i, cluster1 in enumerate(longevity_associated_clusters[\"cluster\"].unique()):\n",
    "    for j, cluster2 in enumerate(longevity_associated_clusters[\"cluster\"].unique()):\n",
    "        if i < j:  # Only calculate for unique pairs\n",
    "            cluster1_members = longevity_associated_clusters[longevity_associated_clusters[\"cluster\"] == cluster1][\"members\"].values[0]\n",
    "            cluster2_members = longevity_associated_clusters[longevity_associated_clusters[\"cluster\"] == cluster2][\"members\"].values[0]\n",
    "            cluster1_indices = [protein_index[member] for member in cluster1_members]\n",
    "            cluster2_indices = [protein_index[member] for member in cluster2_members]\n",
    "            inter_cluster_identities = [\n",
    "                pident_matrix[i, j] for i in cluster1_indices for j in cluster2_indices if i != j\n",
    "            ]\n",
    "            # Calculate average identity between clusters\n",
    "            avg_identity = np.mean(inter_cluster_identities) if inter_cluster_identities else 0\n",
    "            cluster_similarities[(cluster1, cluster2)] = avg_identity\n",
    "\n",
    "# Plot clusters in a grid with inter-cluster connections\n",
    "plt.figure(figsize=(16, 16))\n",
    "grid_size = int(np.ceil(np.sqrt(len(longevity_associated_clusters))))\n",
    "cluster_positions = {}\n",
    "\n",
    "# Plot each cluster\n",
    "for idx, (index, cluster) in enumerate(longevity_associated_clusters.iterrows()):\n",
    "    row, col = divmod(idx, grid_size)\n",
    "    cluster_position = (col * 3, -row * 3)  # Adjust spacing for grid layout\n",
    "    cluster_positions[cluster[\"cluster\"]] = cluster_position\n",
    "    \n",
    "    # Define circle properties\n",
    "    circle_radius = 0.6 + 0.1 * len(cluster[\"members\"])\n",
    "    circle = plt.Circle(cluster_position, circle_radius, color='black', fill=False, \n",
    "                        linewidth=cluster[\"average_silhouette_pident\"] * 4)\n",
    "    plt.gca().add_artist(circle)\n",
    "    \n",
    "    # Position proteins within the cluster circle\n",
    "    angles = np.linspace(0, 2 * np.pi, len(cluster[\"members\"]), endpoint=False)\n",
    "    for i, protein in enumerate(cluster[\"members\"]):\n",
    "        protein_color = get_longevity_category(protein[:2])\n",
    "        x = cluster_position[0] + circle_radius * 0.7 * np.cos(angles[i])\n",
    "        y = cluster_position[1] + circle_radius * 0.7 * np.sin(angles[i])\n",
    "        \n",
    "        # Make representative protein larger\n",
    "        marker_size = 12 if protein == cluster[\"members\"][0] else 8\n",
    "        plt.plot(x, y, 'o', color=protein_color, markersize=marker_size)\n",
    "        plt.text(x, y, protein, fontsize=6, ha='center', va='center')\n",
    "        \n",
    "        # Draw internal connections within cluster based on pairwise identities\n",
    "        for j in range(i + 1, len(cluster[\"members\"])):\n",
    "            x2 = cluster_position[0] + circle_radius * 0.7 * np.cos(angles[j])\n",
    "            y2 = cluster_position[1] + circle_radius * 0.7 * np.sin(angles[j])\n",
    "            plt.plot([x, x2], [y, y2], color=\"gray\", linewidth=1)\n",
    "\n",
    "# Add inter-cluster connections based on average identity scores\n",
    "for (cluster1, cluster2), avg_identity in cluster_similarities.items():\n",
    "    pos1 = cluster_positions[cluster1]\n",
    "    pos2 = cluster_positions[cluster2]\n",
    "    line_width = max(0.5, avg_identity * 5)  # Set minimum line width for visibility\n",
    "    plt.plot([pos1[0], pos2[0]], [pos1[1], pos2[1]], color=\"blue\", linewidth=line_width, alpha=0.6)\n",
    "\n",
    "# Display the plot\n",
    "plt.axis('off')\n",
    "plt.title(\"Longevity-Associated Clusters Network (With Inter-Cluster Connections by Identity)\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping convex hull for cluster with members ['efXP_008143519.2', 'efXP_008143519.2', 'efXP_008143519.2', 'efXP_008143519.2', 'efXP_008143519.2', 'pnCAK6436446.1', 'pnCAK6436446.1', 'pnCAK6436446.1', 'pnCAK6436446.1', 'pnCAK6436446.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['efXP_027987183.2', 'efXP_027987183.2', 'efXP_027987183.2', 'enKAK1329177.1', 'enKAK1329177.1', 'enKAK1329177.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['enKAK1332890.1', 'enKAK1332890.1', 'enKAK1332890.1', 'enKAK1332890.1', 'enKAK1332890.1', 'efXP_054584419.1', 'efXP_054584419.1', 'efXP_054584419.1', 'efXP_054584419.1', 'efXP_054584419.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['mdXP_059516705.1', 'mdXP_059516705.1', 'mdXP_059516705.1', 'mdXP_059516705.1', 'mmXP_036189764.1', 'mmXP_036189764.1', 'mmXP_036189764.1', 'mmXP_036189764.1', 'mmXP_036189764.1', 'mdXP_059516705.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['mdXP_059563598.1', 'mdXP_059563598.1', 'pkXP_036296060.1', 'pkXP_036296060.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['mlXP_006093009.1', 'mbXP_005867846.1', 'mbXP_005867846.1', 'mlXP_006093009.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['mlXP_014322760.1', 'mlXP_014322760.1', 'mbXP_014398738.1', 'mbXP_014398738.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['mlXP_023605794.1', 'mlXP_023605794.1', 'efXP_008138630.2', 'efXP_008138630.2'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['mmXP_036171279.1', 'mlXP_023599139.1', 'mmXP_036171279.1', 'mlXP_023599139.1', 'mmXP_036171279.1', 'mmXP_036171279.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['mmXP_036193230.1', 'mmXP_036193230.1', 'mdXP_059518678.1', 'mdXP_059518678.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['paXP_006906895.1', 'paXP_006906895.1', 'pvXP_011364054.1', 'pvXP_011364054.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['paXP_024903837.1', 'pgXP_039707134.1', 'paXP_024903837.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pdXP_028358869.1', 'pdXP_028358869.1', 'phXP_045672967.1', 'phXP_045672967.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pdXP_028372914.1', 'pdXP_028372914.1', 'phXP_045695578.1', 'phXP_045695578.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pdXP_028389852.2', 'pdXP_028389852.2', 'phXP_045716662.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pdXP_035870881.1', 'phXP_045673197.1', 'phXP_045673197.1', 'pdXP_035870881.1', 'phXP_045673197.1', 'pdXP_035870881.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pdXP_035883993.1', 'pdXP_035883993.1', 'phXP_045684172.1', 'phXP_045684172.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pgXP_039723996.1', 'paXP_024900139.1', 'paXP_024900139.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pkXP_036271442.1', 'pnCAK6442429.1', 'pnCAK6442429.1', 'pkXP_036271442.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pkXP_036275965.1', 'pkXP_036275965.1', 'pnCAK6434165.1', 'pnCAK6434165.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pkXP_036279742.1', 'pkXP_036279742.1', 'pkXP_036279742.1', 'pkXP_036279742.1', 'pkXP_036279742.1', 'pkXP_036279742.1', 'pnCAK6446419.1', 'pnCAK6446419.1', 'pnCAK6446419.1', 'pnCAK6446419.1', 'pnCAK6446419.1', 'pnCAK6446419.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pkXP_036285987.1', 'pkXP_036285987.1', 'pkXP_036285987.1', 'pkXP_036285987.1', 'pkXP_036285987.1', 'pnCAK6444051.1', 'pnCAK6444051.1', 'pnCAK6444051.1', 'pnCAK6444051.1', 'pnCAK6444051.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pkXP_036291743.1', 'pnCAK6435247.1', 'pnCAK6435247.1', 'pnCAK6435247.1', 'pkXP_036291743.1', 'pkXP_036291743.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pkXP_036292046.1', 'pkXP_036292046.1', 'pkXP_036292046.1', 'pkXP_036292046.1', 'pkXP_036292046.1', 'pnCAK6435275.1', 'pnCAK6435275.1', 'pnCAK6435275.1', 'pnCAK6435275.1', 'pnCAK6435275.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pkXP_036308682.1', 'pkXP_036308682.1', 'pkXP_036308682.1', 'pnCAK6439367.1', 'pnCAK6439367.1', 'pnCAK6439367.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pkXP_036312243.1', 'pkXP_036312243.1', 'pkXP_036312243.1', 'pnCAK6443689.1', 'pnCAK6443689.1', 'pnCAK6443689.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pkXP_045435582.1', 'pkXP_045435582.1', 'pnCAK6435938.1', 'pnCAK6435938.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pkXP_045443470.1', 'pkXP_045443470.1', 'pkXP_045443470.1', 'pkXP_045443470.1', 'pnCAK6443898.1', 'pnCAK6443898.1', 'pnCAK6443898.1', 'pnCAK6443898.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pnCAK6436451.1', 'pnCAK6436451.1', 'pnCAK6436451.1', 'pnCAK6436451.1', 'pkXP_036294113.1', 'pnCAK6436451.1', 'pkXP_036294113.1', 'pnCAK6436451.1', 'pkXP_036294113.1', 'pkXP_036294113.1', 'pkXP_036294113.1', 'pkXP_036294113.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pnCAK6440731.1', 'pnCAK6440731.1', 'pkXP_036299857.1', 'pkXP_036299857.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pnCAK6449137.1', 'pnCAK6449137.1', 'pkXP_036284177.1', 'pkXP_036284177.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pvXP_011355853.1', 'pgXP_039710342.1', 'pgXP_039710342.1', 'pvXP_011355853.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pvXP_023384801.1', 'pvXP_023384801.1', 'raXP_036075044.1'] due to Qhull precision error.\n",
      "Skipping convex hull for cluster with members ['pvXP_023388348.1', 'pvXP_023388348.1', 'pvXP_023388348.1', 'pvXP_023388348.1', 'enKAK1339103.1', 'enKAK1339103.1', 'enKAK1339103.1', 'enKAK1339103.1'] due to Qhull precision error.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import ConvexHull, QhullError\n",
    "\n",
    "# Define longevity-associated colors\n",
    "color_map = {\n",
    "    \"short\": \"green\",\n",
    "    \"average\": \"yellow\",\n",
    "    \"long\": \"red\"\n",
    "}\n",
    "\n",
    "# Function to categorize longevity based on prefix\n",
    "def get_longevity_category(prefix):\n",
    "    if prefix in {\"sb\", \"pn\", \"pk\", \"mo\", \"pd\", \"pv\", \"pa\"}:\n",
    "        return \"short\"\n",
    "    elif prefix in {\"en\", \"ef\", \"ph\", \"aj\", \"ra\", \"pg\"}:\n",
    "        return \"average\"\n",
    "    elif prefix in {\"mb\", \"md\", \"ml\", \"mm\", \"dr\", \"rf\"}:\n",
    "        return \"long\"\n",
    "    return \"unknown\"\n",
    "\n",
    "# Build a NetworkX graph for clusters\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes and intra-cluster edges\n",
    "for cluster in filtered_clusters:\n",
    "    members = cluster[\"members\"]\n",
    "    representative = members[0]\n",
    "    \n",
    "    # Get the longevity category, then map it to a color\n",
    "    longevity_category = get_longevity_category(representative[:2])\n",
    "    cluster_color = color_map.get(longevity_category, \"gray\")  # Default to gray if unknown\n",
    "    \n",
    "    # Add the representative node to the graph\n",
    "    G.add_node(representative, color=cluster_color, size=300, label=representative)\n",
    "    \n",
    "    # Add each protein in the cluster to the graph and connect them with intra-cluster edges\n",
    "    for i, protein1 in enumerate(members):\n",
    "        # Add each protein node with the cluster color\n",
    "        G.add_node(protein1, color=cluster_color, size=150, label=protein1)\n",
    "        \n",
    "        # Connect proteins within the cluster based on pairwise identities\n",
    "        for j in range(i + 1, len(members)):\n",
    "            protein2 = members[j]\n",
    "            identity = pident_matrix[protein_index[protein1], protein_index[protein2]]\n",
    "            if identity > 0:\n",
    "                G.add_edge(protein1, protein2, weight=identity * 2)  # Scale for visualization\n",
    "\n",
    "# Add inter-cluster edges based on silhouette scores or average identities between clusters\n",
    "# `cluster_similarities` should be defined as {(cluster1, cluster2): avg_identity, ...}\n",
    "for (cluster1, cluster2), avg_identity in cluster_similarities.items():\n",
    "    if avg_identity > 0:  # Only draw edges with meaningful identity\n",
    "        G.add_edge(cluster1, cluster2, weight=avg_identity, style=\"dotted\")  # Dotted style for inter-cluster\n",
    "\n",
    "# Draw the network with clusters arranged in a spring layout\n",
    "plt.figure(figsize=(15, 15))\n",
    "pos = nx.spring_layout(G, k=0.5)  # Adjust layout to avoid overlap\n",
    "\n",
    "# Draw nodes with colors and labels\n",
    "node_colors = [G.nodes[n][\"color\"] for n in G.nodes]\n",
    "node_sizes = [G.nodes[n][\"size\"] for n in G.nodes]\n",
    "nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=node_sizes, alpha=0.8, edgecolors='black')\n",
    "nx.draw_networkx_labels(G, pos, labels={n: G.nodes[n][\"label\"] for n in G.nodes}, font_size=8, font_color=\"white\")\n",
    "\n",
    "# Draw intra-cluster edges\n",
    "intra_edges = [(u, v) for u, v, d in G.edges(data=True) if d.get(\"style\") != \"dotted\"]\n",
    "intra_weights = [G[u][v][\"weight\"] for u, v in intra_edges]\n",
    "nx.draw_networkx_edges(G, pos, edgelist=intra_edges, width=intra_weights, alpha=0.6, edge_color=\"gray\")\n",
    "\n",
    "# Draw inter-cluster edges with dotted style\n",
    "inter_edges = [(u, v) for u, v, d in G.edges(data=True) if d.get(\"style\") == \"dotted\"]\n",
    "inter_weights = [G[u][v][\"weight\"] for u, v in inter_edges]\n",
    "nx.draw_networkx_edges(G, pos, edgelist=inter_edges, width=inter_weights, style=\"dotted\", edge_color=\"blue\")\n",
    "\n",
    "# Optionally add convex hull around clusters, handling potential errors\n",
    "for idx, cluster in enumerate(filtered_clusters):\n",
    "    members = cluster[\"members\"]\n",
    "    cluster_positions = np.array([pos[protein] for protein in members])\n",
    "    if len(cluster_positions) > 2:  # ConvexHull requires at least 3 points\n",
    "        try:\n",
    "            hull = ConvexHull(cluster_positions)\n",
    "            hull_points = cluster_positions[hull.vertices]\n",
    "            plt.plot(hull_points[:, 0], hull_points[:, 1], 'k--', lw=1)\n",
    "        except QhullError:\n",
    "            print(f\"Skipping convex hull for cluster with members {members} due to Qhull precision error.\")\n",
    "\n",
    "plt.title(\"Longevity-Associated Clusters Network (With Inter-Cluster Connections by Identity)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Example setup assuming `filtered_clusters` is a list of dictionaries with cluster data\n",
    "# Each dictionary in `filtered_clusters` contains \"members\" and \"representative\" keys\n",
    "\n",
    "# Define longevity-associated colors\n",
    "color_map = {\n",
    "    \"short\": \"green\",\n",
    "    \"average\": \"yellow\",\n",
    "    \"long\": \"red\"\n",
    "}\n",
    "\n",
    "# Function to categorize longevity based on prefix\n",
    "def get_longevity_category(prefix):\n",
    "    if prefix in {\"sb\", \"pn\", \"pk\", \"mo\", \"pd\", \"pv\", \"pa\"}:\n",
    "        return \"short\"\n",
    "    elif prefix in {\"en\", \"ef\", \"ph\", \"aj\", \"ra\", \"pg\"}:\n",
    "        return \"average\"\n",
    "    elif prefix in {\"mb\", \"md\", \"ml\", \"mm\", \"dr\", \"rf\"}:\n",
    "        return \"long\"\n",
    "    return \"unknown\"\n",
    "\n",
    "# Build a NetworkX graph for representative proteins only\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add representative nodes based on filtered_clusters\n",
    "for cluster in filtered_clusters:\n",
    "    representative = cluster[\"members\"][0]  # Representative protein of the cluster\n",
    "    longevity_category = get_longevity_category(representative[:2])\n",
    "    cluster_color = color_map.get(longevity_category, \"gray\")\n",
    "    \n",
    "    # Add representative protein node to the graph\n",
    "    G.add_node(representative, color=cluster_color, size=500, label=representative)\n",
    "\n",
    "# Add inter-cluster edges based on average identities between clusters\n",
    "# Assuming `cluster_similarities` is a dictionary {(cluster1, cluster2): avg_identity, ...}\n",
    "for (cluster1, cluster2), avg_identity in cluster_similarities.items():\n",
    "    if avg_identity > 0:  # Only draw edges with meaningful identity\n",
    "        G.add_edge(cluster1, cluster2, weight=avg_identity)\n",
    "\n",
    "# Draw the network with only representative nodes and inter-cluster connections\n",
    "plt.figure(figsize=(10, 10))\n",
    "pos = nx.spring_layout(G, k=0.5)  # Adjust layout for spacing\n",
    "\n",
    "# Draw representative nodes with colors and labels\n",
    "node_colors = [G.nodes[n][\"color\"] for n in G.nodes]\n",
    "node_sizes = [G.nodes[n][\"size\"] for n in G.nodes]\n",
    "nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=node_sizes, alpha=0.8, edgecolors='black')\n",
    "nx.draw_networkx_labels(G, pos, labels={n: G.nodes[n][\"label\"] for n in G.nodes}, font_size=8, font_color=\"white\")\n",
    "\n",
    "# Draw inter-cluster edges with weights representing average identity\n",
    "edges = G.edges(data=True)\n",
    "weights = [d['weight'] for _, _, d in edges]\n",
    "nx.draw_networkx_edges(G, pos, edgelist=edges, width=weights, edge_color=\"blue\", alpha=0.5)\n",
    "\n",
    "plt.title(\"Longevity-Associated Clusters Network (Only Representative Proteins)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Define color mapping\n",
    "color_mapping = {\n",
    "    'green': {'sb', 'pn', 'pk', 'mo', 'pd', 'pv', 'pa'},\n",
    "    'yellow': {'en', 'ef', 'ph', 'aj', 'ra', 'pg'},\n",
    "    'red': {'mb', 'md', 'ml', 'mm', 'dr', 'rf'}\n",
    "}\n",
    "\n",
    "# Function to determine color based on prefix\n",
    "def get_color(prefix):\n",
    "    for color, prefixes in color_mapping.items():\n",
    "        if prefix in prefixes:\n",
    "            return color\n",
    "    return 'gray'  # Default color if prefix is not found\n",
    "# Load the silhouette scores\n",
    "silhouette_df = silhouette_df  # remember to use the one that is for high id\n",
    "\n",
    "# Load the alignment data\n",
    "alignment_df = pd.read_csv(\"ecmaffil_cluster_aligns.tsv\", sep=\"\\t\", \n",
    "                           names=[\"query\", \"target\", \"evalue\", \"pident\", \"alnlen\", \"qstart\", \"qend\", \"tstart\", \"tend\"])\n",
    "\n",
    "# Load clustering information\n",
    "aggregated_df = pd.read_csv(\"aggregated_ECMAFFIL_clusters.tsv\", sep=\"\\t\")\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes for each protein and assign them to clusters with color\n",
    "for _, row in silhouette_df.iterrows():\n",
    "    protein = row[\"protein\"]\n",
    "    prefix = protein[:2]\n",
    "    cluster_id = row[\"cluster\"]\n",
    "    color = get_color(prefix)\n",
    "    G.add_node(protein, cluster=cluster_id, color=color, pident_silhouette=row[\"pident_silhouette\"], evalue_silhouette=row[\"evalue_silhouette\"])\n",
    "\n",
    "# Add edges within clusters based on pident\n",
    "for _, row in alignment_df.iterrows():\n",
    "    query, target = row[\"query\"], row[\"target\"]\n",
    "    if query in G.nodes and target in G.nodes and G.nodes[query][\"cluster\"] == G.nodes[target][\"cluster\"]:\n",
    "        # Add an edge within the same cluster weighted by pident\n",
    "        G.add_edge(query, target, weight=row[\"pident\"], style=\"solid\")\n",
    "\n",
    "# Add edges between clusters based on silhouette scores\n",
    "for cluster_id in silhouette_df[\"cluster\"].unique():\n",
    "    cluster_members = silhouette_df[silhouette_df[\"cluster\"] == cluster_id][\"protein\"].tolist()\n",
    "    cluster_silhouette = silhouette_df[silhouette_df[\"cluster\"] == cluster_id][[\"pident_silhouette\", \"evalue_silhouette\"]].mean().mean()\n",
    "    \n",
    "    for other_cluster_id in silhouette_df[\"cluster\"].unique():\n",
    "        if cluster_id < other_cluster_id:  # Avoid duplicate edges and self-loops\n",
    "            other_cluster_members = silhouette_df[silhouette_df[\"cluster\"] == other_cluster_id][\"protein\"].tolist()\n",
    "            other_cluster_silhouette = silhouette_df[silhouette_df[\"cluster\"] == other_cluster_id][[\"pident_silhouette\", \"evalue_silhouette\"]].mean().mean()\n",
    "            avg_silhouette_score = (cluster_silhouette + other_cluster_silhouette) / 2\n",
    "\n",
    "            # Connect all proteins between clusters with silhouette score as weight\n",
    "            for protein1 in cluster_members:\n",
    "                for protein2 in other_cluster_members:\n",
    "                    G.add_edge(protein1, protein2, weight=avg_silhouette_score, style=\"bold\")\n",
    "\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(12, 12))\n",
    "pos = nx.spring_layout(G, k=0.15, seed=42)\n",
    "\n",
    "# Draw nodes with color based on prefix mapping\n",
    "node_colors = [G.nodes[node]['color'] for node in G.nodes()]\n",
    "nx.draw_networkx_nodes(G, pos, node_size=100, node_color=node_colors)\n",
    "\n",
    "# Draw edges with thickness based on weights\n",
    "for u, v, data in G.edges(data=True):\n",
    "    if data[\"style\"] == \"solid\":\n",
    "        nx.draw_networkx_edges(G, pos, edgelist=[(u, v)], width=data[\"weight\"] / 10, edge_color=\"black\")  # Scale pident for intra-cluster\n",
    "    else:\n",
    "        nx.draw_networkx_edges(G, pos, edgelist=[(u, v)], width=data[\"weight\"], edge_color=\"gray\")  # Scale silhouette score for inter-cluster\n",
    "\n",
    "# Show node labels\n",
    "nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "\n",
    "# Add title\n",
    "plt.title(\"Protein Clusters as Fully Connected Network (Within and Between Clusters)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
